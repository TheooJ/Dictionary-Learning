{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-34a34f37-059e-45f5-bed0-58452b664fab",
    "deepnote_cell_type": "markdown",
    "id": "pe3N_NYnX3oW"
   },
   "source": [
    "# **Compressed Sensing 2021 Project : Dictionary Learning**\n",
    "Hugo Chardon & Théo Jolivet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-aba25720-4682-42c1-b38c-0672b8ecfee1",
    "deepnote_cell_type": "markdown",
    "id": "7GTEXhceacQ-"
   },
   "source": [
    "## 1 General framework of Dictionary Learning\n",
    "\n",
    "### 1.1 One dictionary to learn them all\n",
    "\n",
    "In the classical setting of dictionary learning, we consider a signal $\\mathbf{x}\\in \\mathbb{R}^N$ and we want to represent it in a basis in which it has a sparse representation. The key idea is to write $\\mathbf{x}$ as a linear combination of $k$ other vectors lying in $\\mathbb{R}^N$, called _atoms_ of a predefined _dictionary_. Such a dictionary will be denoted by a matrix $\\mathbf{D}=[\\mathbf{d}_1, \\dots, \\mathbf{d}_k ] \\in \\mathbb{R}^{N\\times k}$, and we want to find the coefficients $\\alpha_1, \\dots, \\alpha_k$ such that $\\sum_{i=1}^k \\alpha_i \\mathbf{d}_i$ is relatively close to $\\mathbf{x}$ in $\\ell_2$-norm. More precisely, we aim at minimizing : \n",
    "\n",
    "$$\n",
    "\\underset{\\boldsymbol{\\alpha} \\in \\mathbb{R}^k}{\\min} \\ \\dfrac{1}{2} \\lVert \\mathbf{x} - \\mathbf{D} \\boldsymbol{\\alpha} \\rVert_2^2\n",
    "$$\n",
    "\n",
    "In order to enforce a sparse representation of $\\mathbf{x}$ in such a dictionary, we penalize the $\\ell_1$-norm of the $\\boldsymbol{\\alpha}$'s as in the LASSO estimator. We denote $l(\\mathbf{x},\\mathbf{D})$ the optimal value of the $\\ell_1$-_sparse coding_ problem :\n",
    "\n",
    "$$\n",
    "l(\\mathbf{x},\\mathbf{D}) = \\underset{\\boldsymbol{\\alpha} \\in \\mathbb{R}^k}{\\min} \\ \\dfrac{1}{2} \\lVert \\mathbf{x}-\\mathbf{D}\\boldsymbol{\\alpha}\\lVert_2^2 \\ + \\ \\lambda\\lVert\\boldsymbol{\\alpha}\\lVert_1\n",
    "$$\n",
    "\n",
    "To compute the dictionary, we usually have access to $n$ observations following a distribution $p(\\mathbf{x})$, stored in $\\mathbf{X} = [\\mathbf{x}_1, \\dots ,\\mathbf{x}_n] \\in \\mathbb{R}^{N \\times n} $, and we then minimize the _empirical risk_ $f_n(\\mathbf{D}) = \\dfrac{1}{n} \\sum_{i=1}^n l(\\mathbf{x}_i,\\mathbf{D})$. Recall that we aim at minimizing the _expected  risk_ $f(\\mathbf{D}) = \\mathbb{E}_{\\mathbf{x}}[l(\\mathbf{x},\\mathbf{D})]$ which is linked to $f_n$ by $f(\\mathbf{D}) = \\underset{n \\to + \\infty}{\\lim} f_n(\\mathbf{D})$.\n",
    "\n",
    "Famous examples of such dictionaries that are widely used in signal processing are the wavelets or Fourier basis, in which we can find a sparse representation of $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-8c06a22e-cfb1-41c8-9400-e97e6aae5019",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 1.2 Adaptive Dictionary\n",
    "\n",
    "Notable applications in signal processing (denoising, inpainting, etc...) and unsupervised data modeling (recommender systems, document clustering, etc...) called for more scalable and efficient matrix-factorization methods. Adaptive dictionaries were thus introduced in recent years to learn the dictionary instead of using a predefined one, and the optimization now seeks to find the coefficients $\\boldsymbol{\\alpha}$ as well as the dictionary $\\mathbf{D}$.\n",
    "\n",
    "To avoid having arbitrarily large values for the columns of the dictionary (and thus an arbitrarily small $\\boldsymbol{\\alpha}$), we only consider dictionaries which columns have a $\\ell_2$-norm of one at most, that is, dictionaries in the set $\\mathcal{C} = \\{ \\mathbf{D} \\in \\mathbb{R}^{N \\times k} \\ \\text{s.t.} \\ \\forall j = 1,...,k; \\ \\mathbf{d}_j^T \\mathbf{d}_j \\leq 1 \\}$. We can then rewrite the problem as a joint optimization problem : \n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{D} \\in \\mathcal{C}, \\ \\alpha \\in \\mathbb{R}^{k \\times n}}{\\min} \\ \\dfrac{1}{n} \\sum_{i=1}^n (\\dfrac{1}{2} \\lVert\\mathbf{x}_i - \\mathbf{D} \\boldsymbol{\\alpha}_i \\lVert_2^2 \\ + \\ \\lambda \\lVert\\boldsymbol{\\alpha}_i\\lVert_1)\n",
    "$$\n",
    "\n",
    "which is convex with respect to both variables when the other is fixed. We optimize the objective function with respect to both the dictionary $\\mathbf{D} \\in \\mathbb{R}^{N \\times k}$ and the coefficients $\\boldsymbol{\\alpha} = [\\boldsymbol{\\alpha}_1,...,\\boldsymbol{\\alpha}_n] \\in \\mathbb{R}^{k \\times n}$. Usually, $k$ is a multiple of 2, such as 256, 512 or 1024. Dictionaries with $k>N$ are called _overcomplete_ dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-f616508e-5706-48e3-82ae-e982526a5958",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 2 Simultaneous dictionary learning and classification (based on _Supervised Dictionary Learning_,  NeurIPS '08)\n",
    "\n",
    "We introduce here the core idea presented in the article. Rather than first creating a sparse representation of the data through dictionary representation and then performing a classical task such as classification on the projected data, the authors propose to perform both tasks simultaneously. Without loss of generality, we will focus on binary classification (generalization is not difficult but the core ideas would remain the same with added technicalities).\n",
    "\n",
    "### 2.1 Standard classification task\n",
    "\n",
    "We have $n$ data points $\\mathbf{x}_1, ..., \\mathbf{x}_n$ endowed with labels $y_i = \\pm 1$. We want to learn a function $f(\\mathbf{x}, \\boldsymbol{\\alpha}, \\boldsymbol{\\theta})$ (namely, the parameter $\\boldsymbol{\\theta}$) generally referred to as a soft classifier, such that $\\forall i$, $\\mathrm{sgn}(f(\\mathbf{x}_i)) = y_i$. The parameter $\\boldsymbol{\\theta}$ can be learned as the result of the following optimization procedure :\n",
    "\n",
    "$$\n",
    "\\underset{\\boldsymbol{\\theta}}{\\min} \\ \\sum_{i=1}^n c(y_i f(\\mathbf{x_i}, \\boldsymbol{\\alpha_i}, \\boldsymbol{\\theta})) + \\lambda_2 \\lVert \\boldsymbol{\\theta} \\rVert_2^2\n",
    "$$\n",
    "\n",
    "with $c(u)= \\log(1+e^{-u})$ the logistic loss (convex surrogate of the 0-1 loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-6124c109-13f3-4dce-a42d-bd276850d8e7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 2.2 Simultaneous learning\n",
    "\n",
    "We create a mixed objective function that contains both a classification loss component and a dictionary learning one.\n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{D}, \\boldsymbol{\\theta}, \\boldsymbol{\\alpha}}{\\min} \\ \\sum_{i=1}^n \\left(c(y_i f(\\mathbf{x_i}, \\boldsymbol{\\alpha_i}, \\boldsymbol{\\theta})) + \\lambda_0 \\lVert \\mathbf{x}_i - \\mathbf{D} \\boldsymbol{\\alpha}_i \\rVert_2^2 + \\lambda_1 \\lVert \\boldsymbol{\\alpha}_i \\rVert_1\\right) + \\lambda_2 \\lVert \\boldsymbol{\\theta} \\rVert_2^2 \\qquad (*)\n",
    "$$\n",
    "\n",
    "which can be rewritten as \n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{D}, \\boldsymbol{\\theta}}{\\min} \\ \\sum_{i=1}^n \\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i)\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "\\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i) = \\underset{\\boldsymbol{\\alpha}_i}{\\min} \\ \\mathcal{S}(\\boldsymbol{\\alpha}_i, \\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i)\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\mathcal{S}(\\boldsymbol{\\alpha}_i, \\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i) = c(y_i f(\\mathbf{x_i}, \\boldsymbol{\\alpha_i}, \\boldsymbol{\\theta})) + \\lambda_0 \\lVert \\mathbf{x}_i - \\mathbf{D} \\boldsymbol{\\alpha}_i \\rVert_2^2 + \\lambda_1 \\lVert \\boldsymbol{\\alpha}_i \\rVert_1\n",
    "$$\n",
    "\n",
    "Note that $\\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i)$ is the loss for a single pair of observations $(\\mathbf{x}_i, y_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-9dd0005c-2795-4397-a05c-a98f106055c6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### 2.2.1 A more discriminative approach\n",
    "\n",
    "\n",
    "In order to make the overall model more disriminative between the two classes we want to construct our dictionary such that the loss for a wrong prediction $\\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, -y_i)$ is bigger than the loss for a correct prediction $\\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i)$. The key point here being that the loss itself depends on the dictionary $\\mathbf{D}$ and the codes $\\boldsymbol{\\alpha}_i$'s. We formulate this new idea in the following optimization problem : \n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{D}, \\boldsymbol{\\theta}}{\\min} \\ \\sum_{i=1}^n c\\left(\\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, -y_i) - \\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i)\\right) + \\lambda_2 \\lVert \\boldsymbol{\\theta} \\rVert^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-2724b4fb-a338-4cfe-8194-0fdd1ac99e2e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### 2.2.2 The trade-off\n",
    "\n",
    "This last problem is harder to solve than $(*)$ so we compromise between the two and introduce a trade-off parameter $\\mu$ to solve a composite optimization problem :\n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{D}, \\boldsymbol{\\theta}}{\\min} \\ \\sum_{i=1}^n \\left[ \\mu \\, c\\left(\\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, -y_i) - \\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i)\\right) + (1-\\mu) \\, \\mathcal{S}^*(\\mathbf{x}_i, \\mathbf{D}, \\boldsymbol{\\theta}, y_i)\\right] + \\lambda_2 \\lVert \\boldsymbol{\\theta} \\rVert^2 \\qquad (**)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-c0272b82-4d70-4492-a29f-50bf20cd354f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### 2.2.3 From learnt dictionary to classification\n",
    "\n",
    "Once we have learnt both the dictionary and the classifier's parameters, we use them to predict the labels of new (or test) examples. given a new example $\\mathbf{x}$, its label is predicted by comparing $\\mathcal{S}^*(\\mathbf{x}, \\mathbf{D}, \\boldsymbol{\\theta}, -1)$ and $\\mathcal{S}^*(\\mathbf{x}, \\mathbf{D}, \\boldsymbol{\\theta}, 1)$. The attributed label is the one for which $\\mathcal{S}^*$ is the lowest. Therefore, we note that a new prediction requires to compute the dictionary representation of the new example : what we refer to as _supervised sparse coding_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-722eb9d0-7cd7-4428-a5aa-fffe1f22eebc",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 2.3 Implementation\n",
    "\n",
    "Solving the optimization problem $(**)$ is carried out by alternate block coordinate descent. We alternate between :\n",
    "\n",
    "(i) _Supervised sparse coding_ : this step aims at computing the representations $\\boldsymbol{\\alpha}_i$'s of the datapoints $\\mathbf{x}_i$ in the dictionary $\\mathbf{D}$ with the classifier's parameter $\\boldsymbol{\\theta}$ fixed. This step amounts to computing the above-defined $\\mathcal{S^*}$ and the $\\boldsymbol{\\alpha}$ that minimizes it, for both $y_i$ and $-y_i$.\n",
    "\n",
    "(ii) _Supervised dictionary update_ : this time, the $\\boldsymbol{\\alpha}_i$'s are fixed and we want to update the dictionary $\\mathbf{D}$ and the classifier's parameter $\\boldsymbol{\\theta}$.\n",
    "\n",
    "\n",
    "Regarding the step $(i)$ in the algorithm described above, the authors suggest using a method known as _fixed-point continuation method_ which is a very general framework for this class of optimization problems. We propose here to compare two approaches : one using the python library cvxpy (in which the optimization method used is not specified) and a _manual_ method (that is, an optimization algorithm written from scratch and inspired by the LASSO implementation of coordinate subgradient descent).\n",
    "\n",
    "Hereafter we describe and implement the algorithm _Supervised Dictionary Learning_ proposed by the authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00003-d8a03d15-4fa0-45e6-b988-1c0471d0f7ec",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 90932,
    "execution_start": 1616624910269,
    "is_code_hidden": false,
    "output_cleared": false,
    "source_hash": "46ea2166",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvxpy==1.1.11 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (1.1.11)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from cvxpy==1.1.11) (0.6.2.post5)\n",
      "Requirement already satisfied: ecos>=2 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from cvxpy==1.1.11) (2.0.10)\n",
      "Requirement already satisfied: scs>=1.1.6 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from cvxpy==1.1.11) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from cvxpy==1.1.11) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from cvxpy==1.1.11) (1.8.1)\n",
      "Requirement already satisfied: qdldl in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from osqp>=0.4.1->cvxpy==1.1.11) (0.1.5.post2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (4.64.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp38-cp38-macosx_10_14_x86_64.whl (228.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.5/228.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from tensorflow) (4.3.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.7/961.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from tensorflow) (61.2.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp38-cp38-macosx_10_10_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.2/167.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/test-project/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=253bf1ddf255d00a523ffe44a821cd3f8596028a5b5f1343476e7c62c6cf893f\n",
      "  Stored in directory: /Users/admin/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, werkzeug, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.11.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.47.0 h5py-3.7.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 werkzeug-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install cvxpy==1.1.11\n",
    "!pip install matplotlib\n",
    "!pip install tqdm\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00009-22a7b49c-a5c1-431a-bb89-a81b01d2758f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1616625129708,
    "source_hash": "18ac30d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import cvxpy as cp\n",
    "from numpy import random as rd\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction import image\n",
    "from tqdm import trange\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-ef91d8cc-0a7a-4f29-87ae-00800929229b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "In the cell below we define some elementary functions and an optimization procedure used to compute the step $(i)$ (Supervised sparse coding) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00005-39aac472-a829-42ec-ac83-527e95fdbee8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17,
    "execution_start": 1616632616040,
    "source_hash": "ca17dff8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supervised sparse coding\n",
    "# w and b are the linear classifier parameters, they are fixed for this step\n",
    "\n",
    "def loss(x, D, w, b, alpha, y, lambda0=1e-3):\n",
    "    return cp.logistic(y * (cp.sum(cp.multiply(w, alpha)) + b)) + lambda0 * cp.norm2(x - D @ alpha) **2\n",
    "\n",
    "\n",
    "def objective(x, D, w, b, alpha, y, lambda0=1e-3, lambda1=1e-3):\n",
    "    return loss(x, D, w, b, alpha, y, lambda0) + lambda1 * cp.norm1(alpha)\n",
    "\n",
    "\n",
    "# Computing the vector alpha\n",
    "# This function will be used in the main algorithm for the alphas update step\n",
    "def supervised_sparse_coding(x, D, w, b, y, reconstruction_param, regularization_param, require_opt_value=False):\n",
    "    \"\"\" Supervised sparse coding.\n",
    "\n",
    "        :param x: the observation of which we want the dictionary representation\n",
    "        :param D: dictionary\n",
    "        :param w: weights of the function f\n",
    "        :param b: bias of the function f\n",
    "        :param y: labels of the observations\n",
    "        :param reconstruction_param: reconstruction error parameter\n",
    "        :param regularization_param: l1 regularization parameter\n",
    "\n",
    "        :return: coefficients alpha (if require_opt_value is False) or minimal value of the objective (if require_opt_value is True)\n",
    "    \"\"\"\n",
    "\n",
    "    k = D.shape[1] # Number of atoms in the dictionary = number of columns in D\n",
    "    alpha = cp.Variable(k)\n",
    "    lambda0 = cp.Parameter(nonneg=True)\n",
    "    lambda1 = cp.Parameter(nonneg=True)\n",
    "\n",
    "    problem = cp.Problem(cp.Minimize(objective(x, D, w, b, alpha, y, lambda0, lambda1)))\n",
    "\n",
    "    lambda0.value = reconstruction_param\n",
    "    lambda1.value = regularization_param\n",
    "\n",
    "    problem.solve(solver=cp.SCS, max_iters=5000)\n",
    "    #problem.solve(solver='CVXOPT')\n",
    "\n",
    "    # In some cases we need the optimal value S^*, in some other cases we need the optimal alpha (i.e. argmin)\n",
    "\n",
    "    if require_opt_value:\n",
    "        return problem.value\n",
    "    else:\n",
    "        return alpha.value\n",
    "\n",
    "\n",
    "def make_prediction(x, D, w, b, reconstruction_param, regularization_param):\n",
    "    pos_loss = supervised_sparse_coding(x, D, w, b, 1, reconstruction_param, regularization_param, require_opt_value=True)\n",
    "    neg_loss = supervised_sparse_coding(x, D, w, b, -1, reconstruction_param, regularization_param, require_opt_value=True)\n",
    "\n",
    "    predicted_label = 1 if pos_loss < neg_loss else -1 # Pseudo-classifier as a plug-in\n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00011-c5605bc7-3dab-40fc-a237-a6abaf90e6f6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1199,
    "execution_start": 1616632616891,
    "source_hash": "49a10f43",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/admin/Desktop/ALL/ENS/StatML/Compressed Sensing/Dictionary Learning (GitHub)/Compressed_Sensing.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000013?line=11'>12</a>\u001b[0m lambda0_test \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000013?line=12'>13</a>\u001b[0m lambda1_test \u001b[39m=\u001b[39m \u001b[39m0.15\u001b[39m \u001b[39m*\u001b[39m lambda0_test\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000013?line=14'>15</a>\u001b[0m alpha_opt \u001b[39m=\u001b[39m supervised_sparse_coding(x\u001b[39m=\u001b[39;49mtest_vector, D\u001b[39m=\u001b[39;49mdictionary, w\u001b[39m=\u001b[39;49mw, b\u001b[39m=\u001b[39;49mb, y\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, reconstruction_param\u001b[39m=\u001b[39;49mlambda0_test, regularization_param\u001b[39m=\u001b[39;49mlambda1_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000013?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(alpha_opt)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000013?line=17'>18</a>\u001b[0m random_alpha \u001b[39m=\u001b[39m rd\u001b[39m.\u001b[39mrandn(k)\n",
      "\u001b[1;32m/Users/admin/Desktop/ALL/ENS/StatML/Compressed Sensing/Dictionary Learning (GitHub)/Compressed_Sensing.ipynb Cell 13'\u001b[0m in \u001b[0;36msupervised_sparse_coding\u001b[0;34m(x, D, w, b, y, reconstruction_param, regularization_param, require_opt_value)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=14'>15</a>\u001b[0m \u001b[39m\"\"\" Supervised sparse coding.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=16'>17</a>\u001b[0m \u001b[39m    :param x: the observation of which we want the dictionary representation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=24'>25</a>\u001b[0m \u001b[39m    :return: coefficients alpha (if require_opt_value is False) or minimal value of the objective (if require_opt_value is True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=25'>26</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=27'>28</a>\u001b[0m k \u001b[39m=\u001b[39m D\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m# Number of atoms in the dictionary = number of columns in D\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=28'>29</a>\u001b[0m alpha \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mVariable(k)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=29'>30</a>\u001b[0m lambda0 \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mParameter(nonneg\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000012?line=30'>31</a>\u001b[0m lambda1 \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mParameter(nonneg\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cp' is not defined"
     ]
    }
   ],
   "source": [
    "# Test of alphas update\n",
    "\n",
    "N = 1000\n",
    "k = 100\n",
    "\n",
    "test_vector = rd.randn(N)\n",
    "dictionary = rd.randn(N, k)\n",
    "\n",
    "w = rd.randn(k)\n",
    "b = rd.randn()\n",
    "\n",
    "lambda0_test = 0.5\n",
    "lambda1_test = 0.15 * lambda0_test\n",
    "\n",
    "alpha_opt = supervised_sparse_coding(x=test_vector, D=dictionary, w=w, b=b, y=1, reconstruction_param=lambda0_test, regularization_param=lambda1_test)\n",
    "print(alpha_opt)\n",
    "\n",
    "random_alpha = rd.randn(k)\n",
    "\n",
    "print('quelconque : ', np.sum((test_vector - dictionary @ random_alpha)**2))\n",
    "print('optimal : ', np.sum((test_vector - dictionary @ alpha_opt)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-4ec2a82a-26ce-4003-906d-d92322e3ec29",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This is a toy example for the computation of $\\boldsymbol{\\alpha}$'s. We want to know if we learn the right coefficients for a random dictionary, and we compare them with random coefficients. The reconstruction error is lower with the optimized coefficients, showing that the learnt coefficients (alpha_opt) perform better at the reconstruction task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-db0bd068-d982-426b-9fce-c9c6163c303c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Then we define the functions needed to compute step $(ii)$ (Supervised dictionary update). We will perform the update of $\\mathbf{D}$ and $\\boldsymbol{\\theta}$ by solving the above stated minimization problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00009-b8c330ba-de97-413e-8a46-dda78f6ebc58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1616632624781,
    "source_hash": "9bede379",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supervised dictionary update\n",
    "\n",
    "def logistic(u):\n",
    "    return np.log(1 + np.exp(-u))\n",
    "\n",
    "\n",
    "def deriv_logistic(u):\n",
    "    return - 1 / (1 + np.exp(u))\n",
    "\n",
    "\n",
    "def cal_S(alpha, x, D, w, b, y, lambda0, lambda1):\n",
    "    return logistic(y * (np.dot(w, alpha) + b)) + lambda0 * np.linalg.norm(x - D @ alpha) ** 2 + lambda1 * np.linalg.norm(alpha, ord=1)\n",
    "\n",
    "\n",
    "def compute_omega(z, mu, alpha_star_neg, alpha_star_pos, x, D, w, b, y):\n",
    "    S_neg = cal_S(alpha_star_neg, x, D, w, b, -y, lambda0, lambda1)\n",
    "    S_pos = cal_S(alpha_star_pos, x, D, w, b, y, lambda0, lambda1)\n",
    "    omega = - mu * z * deriv_logistic(S_neg - S_pos)\n",
    "    \n",
    "    if z == y:\n",
    "        omega += 1 - mu\n",
    "\n",
    "    return omega\n",
    "\n",
    "\n",
    "def compute_gradient(X, D, w, b, y, alpha_star_neg, alpha_star_pos, mu, lambda0, lambda1):\n",
    "    '''\n",
    "    :param X: the whole dataset given as a matrix. here we assume that each data point is a column of X so we have to be careful\n",
    "            regarding the potential need to transpose the input matrix\n",
    "    :param D: dictionary\n",
    "    :param w: weights of the classifier\n",
    "    :param b: bias of the classifier\n",
    "    :param y: labels associated with each observation, {-1,1} convention\n",
    "    :param alpha_star_neg: best alpha if the label was negative\n",
    "    :param alpha_star_neg: best alpha if the label was positive\n",
    "    :param mu: classification/generation tradeoff\n",
    "    :param lambda0: reconstruction regularization parameter\n",
    "    :param lambda1: l1 regularization parameter\n",
    "\n",
    "    :return: partial gradients with respect to dictionary, weights, bias\n",
    "    '''\n",
    "\n",
    "    partial_grad_dict = np.zeros_like(D)\n",
    "    partial_grad_weights = np.zeros_like(w)\n",
    "    partial_grad_bias = np.zeros_like(b)\n",
    "    n = X.shape[0]\n",
    "\n",
    "    for i in range(n):\n",
    "        omega_i_neg = compute_omega(-1, mu, alpha_star_neg, alpha_star_pos, X[i], D, w, b, y[i])\n",
    "        omega_i_pos = compute_omega(1, mu, alpha_star_neg, alpha_star_pos, X[i], D, w, b, y[i])\n",
    "\n",
    "        partial_grad_dict += omega_i_pos * np.outer(X[i] - D @ alpha_star_pos, alpha_star_pos) + omega_i_neg * np.outer(X[i] - D @ alpha_star_neg, alpha_star_neg)\n",
    "        partial_grad_weights += omega_i_pos * deriv_logistic(np.dot(w, alpha_star_pos) + b) * alpha_star_pos - omega_i_neg * deriv_logistic(np.dot(w, alpha_star_neg) + b) * alpha_star_neg\n",
    "        partial_grad_bias += omega_i_pos * deriv_logistic(np.dot(w, alpha_star_pos) + b) - omega_i_neg * deriv_logistic(np.dot(w, alpha_star_neg) + b)\n",
    "\n",
    "    partial_grad_dict *= -2 * lambda0\n",
    "    \n",
    "    return partial_grad_dict, partial_grad_weights, partial_grad_bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-0073239d-b2cf-4a30-815c-72763a5c9d94",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "To perform part $(ii)$ described above, we also use a projected gradient descent. The projection is only done for the dictionaries, by normalizing its columns if necessary (that is replacing the $j$-th column $\\mathbf{d}_j$ by $\\frac{\\mathbf{d}_j}{\\lVert \\mathbf{d}_j \\rVert_2}$ if $\\lVert \\mathbf{d}_j \\rVert_2 > 1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00014-4a8f8550-12a7-4c5f-8a03-cf42fc52fee9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1616632626437,
    "source_hash": "d999b20a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (projected) gradient descent on D, w and b (theta is just a packing of (w,b))\n",
    "\n",
    "def update_parameters(X, D, w, b, y, alpha_star_neg, alpha_star_pos, mu, lambda0, lambda1, maxiter=20, lr=0.5):\n",
    "    for t in trange(maxiter):\n",
    "        partial_grad_dict, partial_grad_weights, partial_grad_bias = compute_gradient(X, D, w, b, y, alpha_star_neg, alpha_star_pos, mu, lambda0, lambda1)\n",
    "        b -= lr * partial_grad_bias\n",
    "        w -= lr * partial_grad_weights\n",
    "        D -= lr * partial_grad_dict\n",
    "        \n",
    "        k = D.shape[1] # Number of atoms in the dictionary\n",
    "        \n",
    "        for j in range(k):\n",
    "            norm_j = np.linalg.norm(D[:,j])\n",
    "            if norm_j > 1:\n",
    "                D[:, j] /= norm_j\n",
    "        \n",
    "        return D, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-56ab8079-567c-42ab-8001-fce467b52526",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now we can implement the main algorithm, which basically amounts to looping over different values of the trade-off parameter $\\mu$ and then iterating until convergence, alternating between $(i)$ and $(ii)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00014-ff509c51-4ae3-4d82-b3e7-b4f89e45d49f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1616632628006,
    "source_hash": "6794242",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global function combining steps (i) and (ii)\n",
    "\n",
    "def supervised_dictionnary_learning(mus, data, labels, nb_atoms, lambda0, lambda1, lambda2, global_maxiter):\n",
    "    ''' Supervised_dictionnary_learning.\n",
    "        Learns a dictionary, the coefficients, and a classifier.\n",
    "\n",
    "    :param mus: array of parameters for classification/generation tradeoff\n",
    "    :param data: the training set. We assume that each datapoint is a column of X so X has a shape size of observations x number of observations\n",
    "    :param labels: labels assoociated with each observation, {-1,1} convention\n",
    "    :param nb_atoms: columns of the dictionary\n",
    "    :param lambda0: reconstruction regularization parameter\n",
    "    :param lambda1: l1 regularization parameter\n",
    "    :param lambda2: l2 regularization parameter\n",
    "    :param global_maxiter: max number of iterations\n",
    "    \n",
    "    :return: best dictionary, best parameter and best precision\n",
    "    '''\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels) # Split the training set\n",
    "    N = X_train.shape[1]\n",
    "\n",
    "    precisions_record = []\n",
    "    thetas = []\n",
    "    dictionaries = []\n",
    "\n",
    "    w = np.zeros(nb_atoms)\n",
    "    b = 0.\n",
    "    D = rd.randn(N,nb_atoms)\n",
    "\n",
    "    # Normalize the columns\n",
    "    for j in range(nb_atoms):\n",
    "        D[:,j] /= np.linalg.norm(D[:,j])\n",
    "\n",
    "    for mu in mus:\n",
    "        for t in range(global_maxiter):\n",
    "            for i,x in enumerate(X_train):\n",
    "                alpha_star_neg = supervised_sparse_coding(x, D, w, b, -1, reconstruction_param=lambda0, regularization_param=lambda1)\n",
    "                alpha_star_pos = supervised_sparse_coding(x, D, w, b, 1, reconstruction_param=lambda0, regularization_param=lambda1)\n",
    "            \n",
    "            D, w, b = update_parameters(X_train, D, w, b, y_train, alpha_star_neg, alpha_star_pos, mu, lambda0, lambda1)\n",
    "\n",
    "        y_test_predict = np.zeros_like(y_test)\n",
    "\n",
    "        for i,x in enumerate(X_test):\n",
    "            y_test_predict[i] = make_prediction(x)\n",
    "        \n",
    "        confusion_matrix_test = confusion_matrix(y_test,y_test_predict)\n",
    "        tp = confusion_matrix_test[0,0]\n",
    "        fp = confusion_matrix_test[1,0]\n",
    "        precision = tp/(tp+fp)\n",
    "\n",
    "        precisions_record.append(precision)\n",
    "        thetas.append((w,b))\n",
    "        dictionaries.append(D)\n",
    "\n",
    "    best_precision = max(precisions_record)\n",
    "    best_index = precisions.index(best_precision)\n",
    "    best_parameter = thetas[best_index]\n",
    "    best_dictionary = dictionaries[best_index]\n",
    "\n",
    "    return best_dictionary, best_parameter, best_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00021-5364de75-e5bd-4f22-ba54-e0bb10f9ea67",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 162505,
    "execution_start": 1616632633898,
    "output_cleared": false,
    "source_hash": "1412953e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py:1246: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  \"Solution may be inaccurate. Try another solver, \"\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  after removing the cwd from sys.path.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-25c4cf02d36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mglobal_maxiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbest_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassif_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupervised_dictionnary_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_atoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_atoms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_maxiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_maxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-567e93c3bc9d>\u001b[0m in \u001b[0;36msupervised_dictionnary_learning\u001b[0;34m(mus, data, labels, nb_atoms, lambda0, lambda1, lambda2, global_maxiter)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0malpha_star_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupervised_sparse_coding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0malpha_star_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupervised_sparse_coding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_star_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_star_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-34f060126f23>\u001b[0m in \u001b[0;36msupervised_sparse_coding\u001b[0;34m(x, D, w, b, y, reconstruction_param, regularization_param, require_opt_value)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mlambda1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularization_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m#problem.solve(solver='CVXOPT')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         data, solving_chain, inverse_data = self.get_problem_data(\n\u001b[0;32m--> 919\u001b[0;31m             solver, gp, enforce_dpp, verbose)\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36mget_problem_data\u001b[0;34m(self, solver, gp, enforce_dpp, verbose)\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0;34mf'{reduction_chain_str}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 )\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolving_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m             safe_to_cache = (\n\u001b[1;32m    593\u001b[0m                 \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/reductions/chain.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, problem, verbose)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Applying reduction {type(r).__name__}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/reductions/dcp2cone/cone_matrix_stuffing.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoeffExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         params_to_objective, flattened_variable = self.stuffed_objective(\n\u001b[0;32m--> 312\u001b[0;31m             problem, extractor)\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Lower equality and inequality to Zero and NonNeg.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mcons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/reductions/dcp2cone/cone_matrix_stuffing.py\u001b[0m in \u001b[0;36mstuffed_objective\u001b[0;34m(self, problem, extractor)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstuffed_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Extract to c.T * x + r; c is represented by a ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mboolean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_mip_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/utilities/coeff_extractor.py\u001b[0m in \u001b[0;36maffine\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mexpr_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical_form\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/utilities/coeff_extractor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mexpr_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical_form\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/atoms/atom.py\u001b[0m in \u001b[0;36mis_dpp\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \"\"\"\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dcp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dgp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dgp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/utilities/performance_utils.py\u001b[0m in \u001b[0;36m_compute_once\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/expressions/expression.py\u001b[0m in \u001b[0;36mis_dcp\u001b[0;34m(self, dpp)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdpp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpp_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_convex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_concave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_convex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_concave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/utilities/performance_utils.py\u001b[0m in \u001b[0;36m_compute_once\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/atoms/atom.py\u001b[0m in \u001b[0;36mis_convex\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_atom_convex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 if not (arg.is_affine() or\n\u001b[0m\u001b[1;32m    174\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_convex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_incr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         (arg.is_concave() and self.is_decr(idx))):\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/utilities/performance_utils.py\u001b[0m in \u001b[0;36m_compute_once\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/expressions/expression.py\u001b[0m in \u001b[0;36mis_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"Is the expression affine?\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_convex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_concave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/utilities/performance_utils.py\u001b[0m in \u001b[0;36m_compute_once\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/atoms/atom.py\u001b[0m in \u001b[0;36mis_concave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_atom_concave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 if not (arg.is_affine() or\n\u001b[0m\u001b[1;32m    191\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_concave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_incr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                         (arg.is_convex() and self.is_decr(idx))):\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/utilities/performance_utils.py\u001b[0m in \u001b[0;36m_compute_once\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m      \"\"\"\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'__cache__'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the global algorithm\n",
    "\n",
    "mus = np.linspace(0,1,10)\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "y = 2 * y - 1\n",
    "nb_atoms = 32\n",
    "lambda0 = 0.5\n",
    "lambda1 = 0.15 * lambda0\n",
    "lambda2 = 1.2e-3\n",
    "global_maxiter = 10\n",
    "\n",
    "best_dictionary, best_parameter, classif_precision = supervised_dictionnary_learning(mus, data=X, labels=y, nb_atoms=nb_atoms, lambda0=lambda0, lambda1=lambda1, lambda2=lambda2, global_maxiter = global_maxiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-586214ee-61d8-47f7-92c9-a3e350b1c2a4",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Note that we cannot directly compare dictionaries because there are an infinity of linear combinations such that $\\mathbf{x} \\approx \\sum_{i=1}^k \\alpha_i \\mathbf{d}_i$ . We can however plot the columns of the dictionaries, for instance in the case of character recognition, a \"7\" is an horizontal bar, an angle and a slantwise bar. We can generalize this idea for more complex images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-5a7fd57b-8cfb-4ef4-acde-694a15c42715",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 2.4 Running the algorithm on real data\n",
    "\n",
    "We are going to run the SDL algorithm on a medical dataset. The breast cancer diagnostic data set has 30 prediction variables and a binary output : the indicator that the individual was diagnosed with breast cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00018-32fb9bfd-2c30-4edd-9b98-ef181dd1e9ed",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 90,
    "execution_start": 1616623324455,
    "source_hash": "219823c5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Presentation of the dataset\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(y)\n",
    "N = X.shape[1]\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-6054c68a-bc57-4d8b-8e11-5670913be7f8",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We now split data between train and test sets. Not only is it necessary to assess the quality of the learnt model, but we also need to evaluate each model obtained for each value of $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00021-0910a496-a61b-4a35-86e0-2a3ecd52744e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1616634741376,
    "source_hash": "fa7d0593",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting of the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-ec945a23-6154-427b-8b97-9a74aad70d4a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Classification benchmark : SVM\n",
    "\n",
    "We first perform the classification task using a classical Support Vector Machine (SVM). For this, we will use the SVM class already available in sklearn as a benchmark.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00025-91d5c809-4b97-49b8-b7c7-8e36512c91b8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 32769,
    "execution_start": 1616634760492,
    "source_hash": "138f5b56",
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "validation_curve() takes 3 positional arguments but 5 positional arguments (and 1 keyword-only argument) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7219ca9fc89d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mC_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvalid_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: validation_curve() takes 3 positional arguments but 5 positional arguments (and 1 keyword-only argument) were given"
     ]
    }
   ],
   "source": [
    "# Plot learning and test scores\n",
    "\n",
    "C_range = np.logspace(-6,-2,50)\n",
    "train_scores, valid_scores = validation_curve(LinearSVC(), X_train, y_train, \"C\", C_range, cv=10)\n",
    "train_scores_mean = np.mean(train_scores,axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores,axis=1)\n",
    "plt.plot(np.log10(C_range),train_scores_mean,label=\"learning scores\")\n",
    "plt.plot(np.log10(C_range),valid_scores_mean,label=\"testing scores\")\n",
    "plt.legend()\n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00024-91fc686f-148a-4ca1-820e-ee8bbe0a7e46",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 100,
    "execution_start": 1616634744115,
    "source_hash": "ae1dbf5c",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-00eb11c4e267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtuned_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "# Cross-validation to find the best regularization parameter\n",
    "\n",
    "tuned_parameters = [{'C': [1, 5, 10, 50, 100, 500, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(svm, tuned_parameters, scoring='precision')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00026-bb407a2e-475a-49ac-98ff-97ebb4b85cee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 122,
    "execution_start": 1616634796958,
    "source_hash": "492cb17",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9230769230769231\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Perform SVM with best value\n",
    "C_best = C_range[np.argmax(valid_scores_mean)]\n",
    "svm = LinearSVC(C=C_best).fit(X_train,y_train)\n",
    "print('Score:', svm.score(X_test,y_test))\n",
    "y_test_predict = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-8287b95e-5a11-4035-a292-752f2d0cf102",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1616634800128,
    "source_hash": "e406aabf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39 10]\n",
      " [ 1 93]]\n",
      "Recall : 0.7959183673469388\n",
      "Precision : 0.975\n"
     ]
    }
   ],
   "source": [
    "# Print relevant metrics\n",
    "\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_predict)\n",
    "print(confusion_matrix_test)\n",
    "\n",
    "tp = confusion_matrix_test[0,0]\n",
    "fp = confusion_matrix_test[1,0]\n",
    "fn = confusion_matrix_test[0,1]\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "print('Recall :', recall)\n",
    "print('Precision :', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-e3edb2f9-b042-425c-88bf-4d32dc4dcd73",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Benchmarking results\n",
    "This will then be our benchmark : we fine-tuned a SVM by cross-validating the regularization parameter C and reached a precision of 97,5% on the breast cancer dataset. Let us find out how the SDL compares with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-000f57e1-935c-4567-89c8-a7ab674e2d84",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 3 Online dictionary learning (based on ICML '09)\n",
    "\n",
    "In this section, we do not consider the classification problem like in Section 2, we are instead interested in purely _reconstructive_ dictionaries. We present the online setting where we dynamically learn the dictionary. This setting is interesting when we consider video streams for instance, where frames come one at a time, or very large datasets where we can't use batch optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-1a05b446-6049-481c-88cc-a5bef859dfc9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 3.1 Online dictionary learning\n",
    "\n",
    "In a similar way as in Section 1, we consider the problem : \n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{D} \\in \\mathcal{C}, \\ \\alpha \\in \\mathbb{R}^{k \\times n}}{\\min} \\ \\dfrac{1}{n} \\sum_{i=1}^n (\\dfrac{1}{2} \\lVert\\mathbf{x}_i - \\mathbf{D} \\boldsymbol{\\alpha}_i \\lVert_2^2 \\ + \\ \\lambda \\lVert\\boldsymbol{\\alpha}_i\\lVert_1) \\qquad (*)\n",
    "$$ \n",
    "\n",
    "At each time step $t=1,...,T$, we sample a signal $\\mathbf{x}_t \\in \\mathbb{R}^{N}$ and adapt the dictionary based on this \"new\" observation. This can be useful for instance if the dataset size is too large, or if information is available in a dynamic way.\n",
    "\n",
    "In our online learning setting, we denote :\n",
    "\n",
    "$\\mathbf{A} = [\\mathbf{a}_1, ..., \\mathbf{a}_k] \\in \\mathbb{R}^{k \\times k} = \\sum_{i=1}^t \\boldsymbol{\\alpha}_i \\boldsymbol{\\alpha}_i^\\top$ \n",
    "\n",
    "$\\mathbf{B} = [\\mathbf{b}_1, ..., \\mathbf{b}_k] \\in \\mathbb{R}^{N \\times k} = \\sum_{i=1}^t \\mathbf{x}_i \\boldsymbol{\\alpha}_i^\\top$\n",
    "\n",
    "These matrices will be helpful when we want to update the dictionary by leveraging the nature of the problem. Note that at time $t$, we don't store all previous information, which could be intensive in memory, but rather use matrices that we update.\n",
    "\n",
    "\n",
    "The online dictionary learning algorithm solves (*) by drawing a sample $\\mathbf{x}_t$ and iterating between 2 steps :\n",
    "\n",
    "(i) _Sparse coding_ : $\\mathbf{D}_{t-1}$ is fixed, and we compute $\\boldsymbol{\\alpha}_t$ with LARS. We update \n",
    "\n",
    "$\\mathbf{A}_t \\leftarrow \\mathbf{A}_{t-1} + \\boldsymbol{\\alpha}_t \\boldsymbol{\\alpha}_t^\\top $\n",
    "\n",
    "$\\mathbf{B}_t \\leftarrow \\mathbf{B}_{t-1} + \\mathbf{x}_t \\boldsymbol{\\alpha}_t^\\top $\n",
    "\n",
    "(ii) _Dictionary update_ : $\\boldsymbol{\\alpha}_t$ is fixed, we solve \n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\mathbf{D}_t & = & \\underset{\\mathbf{D} \\in \\mathcal{C}}{\\min} \\ \\dfrac{1}{t} \\sum_{i=1}^t (\\dfrac{1}{2} \\lVert\\mathbf{x}_i - \\mathbf{D} \\boldsymbol{\\alpha}_i \\lVert_2^2 \\ + \\ \\lambda \\lVert\\boldsymbol{\\alpha}_i\\lVert_1) \\\\ \\\\\n",
    " & = & \\dfrac{1}{t}(\\dfrac{1}{2} Tr(\\mathbf{D}^\\top \\mathbf{D} \\mathbf{A}_t) - Tr(\\mathbf{D}^\\top \\mathbf{B}_t) )\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is to say for $j=1,...,k$ do :\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\mathbf{u}_j & \\leftarrow & \\dfrac{1}{\\mathbf{A}_{jj}}(\\mathbf{b}_j - \\mathbf{D} \\mathbf{a}_j) + \\mathbf{d}_j\\\\ \n",
    "\\mathbf{d}_j & \\leftarrow & \\dfrac{1}{\\text{max}(\\lVert \\mathbf{u}_j \\lVert_2, 1)} \\mathbf{u}_j\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "As opposed to batch methods, this method takes advantage of the structure of the data to significantly reduce computation time. The dictionary is updated using $\\mathbf{D}_{t-1}$ as a warm restart because the dictionaries don't change a lot between updates. Note that we could also consider a _mini-batch setting_, where we sample multiple $\\mathbf{x}_t$'s at each step. In the paper, the authors found that it considerably reduced computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00009-14375aac-f03f-45be-9522-1532a3164e0c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1616635395209,
    "source_hash": "61bcc95f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Online Dictionary Learning for Sparse Coding (ICML 2009)\n",
    "\n",
    "def dictionary_update(D, A, B):\n",
    "    \"\"\" Update the dictionary in online fashion.\n",
    "\n",
    "        :param D: dictionary that is updated\n",
    "        :param A: matrix of alpha*alpha^T, keeps previous information\n",
    "        :param B: matrix of x*alpha^T, keeps previous information\n",
    "\n",
    "        :return D_new: updated dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    D_new = np.zeros_like(D)\n",
    "    \n",
    "    for i in range(D.shape[1]):\n",
    "        D_new[:,i] = 1 / (A[i,i] + 1e-4) * (B[:,i] - D @ A[:,i]) + D[:,i]\n",
    "        D_new[:,i] = 1 / max(np.linalg.norm(D_new[:,i]), 1) * D_new[:,i] # Normalize the columns of the dictionary\n",
    "\n",
    "    return D_new\n",
    "\n",
    "\n",
    "def online_dictionary_learning(X, k, nb_iter=200):\n",
    "    \"\"\" Optimize the cost function with respect to D and alpha alternatively, with single-sample update.\n",
    "\n",
    "        :param X: samples of signal to reconstruct\n",
    "        :param k: number of atoms in the dictionary\n",
    "        :param nb_iter: number of iterations\n",
    "\n",
    "        :return D: learned dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    D = rd.randn(X[0].reshape(-1, 1).shape[0], k)\n",
    "    A = np.zeros((k, k))\n",
    "    B = np.zeros((X[0].reshape(-1, 1).shape[0], k))\n",
    "\n",
    "    iis = np.random.randint(0, X.shape[0], nb_iter)\n",
    "\n",
    "    lambd = 1.2 / np.sqrt(X[0].reshape(-1, 1).shape[0]) # Heuristic for the normalization factor\n",
    "    \n",
    "    reg = Lasso(lambd, max_iter=5000)\n",
    "\n",
    "    for i in range(nb_iter):\n",
    "        X_sample = X[iis[i]]\n",
    "        X_sample = X_sample.reshape(-1, 1)\n",
    "        \n",
    "        reg.fit(D, X_sample) # Update alpha\n",
    "        alpha = reg.coef_\n",
    "\n",
    "        A += np.outer(alpha, alpha)\n",
    "        B += np.outer(X_sample, alpha)\n",
    "\n",
    "        D = dictionary_update(D, A, B) # Update D\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-20893b59-5986-419b-a749-83aeda5da606",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 3.2  Gradient descent to compute the dictionary\n",
    "\n",
    "Usually, the dictionary is updated using classical _stochastic gradient descent_, which for the update of $\\mathbf{D}$ reads : \n",
    "\n",
    "$\\mathbf{D}_{t} = \\Pi_\\mathcal{C}[\\mathbf{D}_{t-1} \\ - \\ \\dfrac{\\rho}{t} \\nabla_\\mathbf{D} l(\\mathbf{x},\\mathbf{D}_{t-1})]$\n",
    "\n",
    "Expanding the loss function after a small update \n",
    "$$ l (\\mathbf{x}, \\mathbf{D+H}) = \\dfrac{1}{2} \\lVert \\mathbf{x} - (\\mathbf{D}+\\mathbf{H})\\boldsymbol{\\alpha} \\rVert^2 + \\ \\lambda \\lVert\\boldsymbol{\\alpha}_i\\lVert_1 = \\dfrac{1}{2} \\lVert \\mathbf{x} - \\mathbf{D} \\boldsymbol{\\alpha} \\rVert^2 + \\ \\lambda \\lVert\\boldsymbol{\\alpha}_i\\lVert_1 - \\langle \\mathbf{x} - \\mathbf{D}\\boldsymbol{\\alpha}, \\mathbf{H}\\boldsymbol{\\alpha} \\rangle + \\dfrac{1}{2} \\lVert \\mathbf{H}\\boldsymbol{\\alpha} \\rVert^2 $$\n",
    "\n",
    "and noting that \n",
    "\n",
    "$$ \\langle \\mathbf{x} - \\mathbf{D}\\boldsymbol{\\alpha}, \\mathbf{H}\\boldsymbol{\\alpha} \\rangle = \\langle (\\mathbf{x} - \\mathbf{D}\\boldsymbol{\\alpha})\\boldsymbol{\\alpha}^\\top , \\mathbf{H} \\rangle_F $$\n",
    "\n",
    "we can identify\n",
    "\n",
    "$$ \\nabla_\\mathbf{D} l (\\mathbf{x}, \\mathbf{D}) = (\\mathbf{D}\\boldsymbol{\\alpha} - \\mathbf{x})\\boldsymbol{\\alpha}^\\top $$\n",
    "\n",
    "For this last equality we used a simple \"trick\" : if $\\mathbf{u} \\in \\mathbb{R}^p$, $\\mathbf{v} \\in \\mathbb{R}^q$, and $\\mathbf{M}$ is a $p\\times q$ matrix, then we can rewrite the scalar product \n",
    "$$\n",
    "\\langle \\mathbf{u}, \\mathbf{M}\\mathbf{v} \\rangle = \\sum_{i=1}^p \\sum_{j=1}^q u_i M_{ij} v_j\n",
    "$$\n",
    "\n",
    "as\n",
    "\n",
    "$$\n",
    "\\sum_{i,j} u_i v_j M_{ij}\n",
    "$$\n",
    "\n",
    "which is the standard Frobenius scalar product $\\langle \\mathbf{u} \\mathbf{v}^\\top, \\mathbf{M} \\rangle_F$ between the matrices $\\mathbf{u} \\mathbf{v}^\\top$ and $\\mathbf{M}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00040-1a131a70-8f28-4b29-9408-7da1c602464f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1616635487568,
    "source_hash": "2bd9ea06",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stochastic gradient descent\n",
    "\n",
    "def grad_i(D, alpha, X_sample):\n",
    "    alpha = alpha.reshape(-1, 1)\n",
    "    return np.outer(D @ alpha - X_sample, alpha)\n",
    "\n",
    "\n",
    "def stochastic_dictionary_update(D_init, alpha, X, maxiter=100, step=1000):\n",
    "    \"\"\" Stochastic gradient descent algorithm (with projection onto the set of Nxk matrices with unit norm columns).\n",
    "\n",
    "        :param D_init: initial value of D before the descent\n",
    "        :param alpha: vector of coefficients\n",
    "        :param X: dataset\n",
    "        :param maxiter: maximum number of iterations\n",
    "        :param step: learning rate\n",
    "\n",
    "        :return D: last updated dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    D = D_init.copy()\n",
    "    \n",
    "    iis = np.random.randint(0, X.shape[0], maxiter) # To sample observations\n",
    "\n",
    "    for i in range(maxiter):\n",
    "        X_sample = X[iis[i]]\n",
    "        X_sample = X_sample.reshape(-1, 1)\n",
    "        \n",
    "        D = D - step / np.sqrt(i + 1) * grad_i(D, alpha, X_sample) # SGD with decaying step\n",
    "        \n",
    "        for i in range(D.shape[1]):\n",
    "            D[:,i] = 1 / max(np.linalg.norm(D[:,i]), 1) * D[:,i] # Projection onto the set C\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def stochastic_dictionary_learning(X, k, nb_iter=200):\n",
    "    \"\"\" Stochastic dictionary learning.\n",
    "\n",
    "        :param X: samples of signal to reconstruct\n",
    "        :param k: number of atoms in the dictionary\n",
    "        :param nb_iter: number of iterations\n",
    "        \n",
    "        :return D: learned dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    D = rd.randn(X[0].reshape(-1, 1).shape[0], k)\n",
    "    \n",
    "    iis = np.random.randint(0, X.shape[0], nb_iter)\n",
    "\n",
    "    lambd = 1.2 / np.sqrt(X[0].reshape(-1, 1).shape[0])\n",
    "    \n",
    "    reg = Lasso(lambd, max_iter=5000)\n",
    "\n",
    "    for i in range(nb_iter):\n",
    "        X_sample = X[iis[i]]\n",
    "        X_sample = X_sample.reshape(-1, 1)\n",
    "        \n",
    "        reg.fit(D, X_sample) # Update alpha\n",
    "        alpha = reg.coef_\n",
    "\n",
    "        D = stochastic_dictionary_update(D, alpha, X) # Update D\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Learning a dictionary from the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00037-da701d9c-495c-45a6-9e76-aa52b3cdd996",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1004,
    "execution_start": 1616635396327,
    "source_hash": "f70d0fa5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(15, 5))\n",
    "for i in range(5) :\n",
    "    axs[i].imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "plt.suptitle(\"Examples of images from the MNIST dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHeCAYAAACGxWgBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcIklEQVR4nO3de3xU9Z3/8fckkCFcMlGIiZGAogIVFXaBpCiIF1qkSpVaxIgaKIK7NQgLtIXVElDXqFilIsXaesULIrW06wVboLLbAq1F0ZWuLiCRICRCIJlJgAmQ8/uD30w4zATmZObMzJm8no/HPLbfb84532+G+N7zmTnne1yGYRgCAAAAAAAxl5boCQAAAAAAkKoougEAAAAAsAlFNwAAAAAANqHoBgAAAADAJhTdAAAAAADYhKIbAAAAAACbUHQDAAAAAGATim4AAAAAAGxC0Q0AAAAAgE0ougHAJi+88IJcLpf+/ve/J3oqlnzwwQe67LLL1KlTJ7lcLm3evDnsdu+//75cLpfef//9uM4vGa1atUoDBgxQhw4d5HK5VFtbm+gpWVZRUSGXy6XHHnss0VNJaYFcqKioSPRUAABxQtENIKUETmgDrw4dOqh3794qLS1VdXW15eM99NBDWrlyZewnmqSOHDmisWPHav/+/XriiSe0dOlS9ezZM9HTSmo1NTW6+eablZmZqcWLF2vp0qXq1KlToqfVonfeeUfz5s1L6BwC/33eeeedYX9+7733BrfZt29fsH/ChAlyuVy69NJLZRhG2OOWlpYG2y19kFBRUaGJEyfq/PPPV4cOHZSXl6crrrhCZWVlkkJzpKXXueeeG4N3I3KvvvqqFi5cGNcxW3Lw4EHNmzePD90AIALtEj0BALDD/fffr/POO0+HDx/Wn//8Zy1ZskTvvPOOPv30U3Xs2DHi4zz00EP6/ve/rxtvvNG+ySaR7du368svv9SvfvWrFguigCuuuEKHDh1SRkZGnGaXnD744AP5fD498MADGjFiRKKnc1rvvPOOFi9enPDCu0OHDvrNb36jX/ziFyF/Q6+99po6dOigw4cPh933f/7nf/Tmm2/qpptusjzutm3bNHjwYGVmZuoHP/iBzj33XO3Zs0cffvihHnnkEc2fP19XXHGFli5datrvzjvvVGFhoaZMmRLs69y5s+Xxo/Hqq6/q008/1fTp0+M6bjgHDx7U/PnzJUlXXnllYicDAEmOohtASho1apQGDRok6fjJcteuXfX444/rd7/7nYqLixM8u+T19ddfS5Kys7NPu21aWpo6dOhg84ySn5X37ODBg5Y+9Ell1157rX7/+9/r3Xff1Q033BDsX79+vXbs2KGbbrpJv/nNb0L2y8zMVEFBge6//35973vfk8vlsjTuE088ofr6em3evDnkKo7Av2WvXr3Uq1cv08/+5V/+Rb169dJtt91maTwAALi8HECbcPXVV0uSduzYIUl67LHHdNlll6lr167KzMzUwIEDtWLFCtM+LpdLDQ0NevHFF4OXk06YMCH486+++kqTJk1Sfn6+3G63zjvvPP3rv/6rGhsbTcfx+/2aMWOGcnJy1KlTJ40ZM0Z79+4NmeO7776rYcOGqVOnTurSpYuuu+46bdmyxbRNVVWVJk6cqO7du8vtduvss8/WDTfcENH9oWvXrg0ePzs7WzfccIP+93//N/jzCRMmaPjw4ZKksWPHyuVynfIbrHD3dF955ZW6+OKL9cknn2j48OHq2LGjLrjgguB7u27dOhUVFSkzM1N9+vTR6tWrTcf88ssv9cMf/lB9+vRRZmamunbtqrFjx4b9/QJjZGZmqnv37nrwwQf1/PPPh71f1q739sorr1RJSYkkafDgwaa/kcB7sWnTJl1xxRXq2LGj/v3f/13S8eJu0qRJys3NVYcOHdS/f3+9+OKLpmOfeGn04sWL1atXL3Xs2FHf/va3VVlZKcMw9MADD6h79+7KzMzUDTfcoP3797c4V+n4v/HixYslyXSZ9MmeeeYZnX/++XK73Ro8eLA++OCDkG0+++wzff/739eZZ56pDh06aNCgQfr9739/yvFPdM455+iKK67Qq6++aup/5ZVXdMkll+jiiy8Ou19aWpruu+8+ffLJJ/rtb38b8XgB27dvV/fu3cPeNnHWWWdZPt6pbNmyRVdffbXpb7SpqSlku9/97ne67rrrglly/vnn64EHHtCxY8eC21x55ZV6++239eWXX4Zc3t7Y2Ki5c+dq4MCB8ng86tSpk4YNG6Y//elPIWMtW7ZMAwcOVJcuXZSVlaVLLrlEP//5z03b1NbWavr06SooKJDb7dYFF1ygRx55JDj3iooK5eTkSJLmz58fnE+ir54AgGTFN90A2oTt27dLkrp27SpJ+vnPf67vfve7Gj9+vBobG7Vs2TKNHTtWb731lq677jpJ0tKlS0MuKT3//PMlSbt371ZhYaFqa2s1ZcoU9e3bV1999ZVWrFihgwcPmi6XnTp1qs444wyVlZWpoqJCCxcuVGlpqV5//fXgNkuXLlVJSYlGjhypRx55RAcPHtSSJUs0dOhQffTRR8GT65tuuklbtmzR1KlTde655+rrr7/WH//4R+3cufOU95euXr1ao0aNUq9evTRv3jwdOnRIixYt0uWXX64PP/xQ5557ru666y6dc845euihh3TPPfdo8ODBys3NtfxeHzhwQNdff71uueUWjR07VkuWLNEtt9yiV155RdOnT9e//Mu/6NZbb9WCBQv0/e9/X5WVlerSpYuk45dqr1+/Xrfccou6d++uiooKLVmyRFdeeaX+8Y9/BL8l/uqrr3TVVVfJ5XJpzpw56tSpk37961/L7XaHzMfO9/bee+9Vnz599MwzzwRvaQj8jUjH7/ceNWqUbrnlFt12223Kzc3VoUOHdOWVV2rbtm0qLS3VeeedpzfeeEMTJkxQbW2tpk2bZhrjlVdeUWNjo6ZOnar9+/fr0Ucf1c0336yrr75a77//vn7yk59o27ZtWrRokWbNmqXnnnuuxX+bu+66S7t379Yf//jHkMunA1599VX5fD7dddddcrlcevTRR/W9731PX3zxhdq3by/peDF5+eWX65xzztHs2bPVqVMnLV++XDfeeKN+85vfaMyYMS3O4US33nqrpk2bpvr6enXu3FlHjx7VG2+8oRkzZrR4aXlgvwceeED333+/xowZY+nb7p49e2r16tVau3Zt8MM4O1RVVemqq67S0aNHg+/RM888o8zMzJBtX3jhBXXu3FkzZsxQ586dtXbtWs2dO1der1cLFiyQdPxvra6uTrt27dITTzwhqfnydq/Xq1//+tcqLi7W5MmT5fP59Oyzz2rkyJH629/+pgEDBkiS/vjHP6q4uFjXXHONHnnkEUnS//7v/+ovf/lL8O/u4MGDGj58uL766ivddddd6tGjh9avX685c+Zoz549WrhwoXJycrRkyRL967/+q8aMGaPvfe97kqRLL73UtvcTABzNAIAU8vzzzxuSjNWrVxt79+41KisrjWXLlhldu3Y1MjMzjV27dhmGYRgHDx407dfY2GhcfPHFxtVXX23q79Spk1FSUhIyzh133GGkpaUZH3zwQcjPmpqaTHMZMWJEsM8wDOPf/u3fjPT0dKO2ttYwDMPw+XxGdna2MXnyZNNxqqqqDI/HE+w/cOCAIclYsGCBxXfFMAYMGGCcddZZRk1NTbDv448/NtLS0ow77rgj2PenP/3JkGS88cYbpz1mYNs//elPwb7hw4cbkoxXX3012PfZZ58Zkoy0tDRj48aNwf733nvPkGQ8//zzwb6T/10MwzA2bNhgSDJeeumlYN/UqVMNl8tlfPTRR8G+mpoa48wzzzQkGTt27DAMIz7vbeDf+eS/hcB78fTTT5v6Fy5caEgyXn755WBfY2OjMWTIEKNz586G1+s1DMMwduzYYUgycnJygn8rhmEYc+bMMSQZ/fv3N44cORLsLy4uNjIyMozDhw+fcr533323Ee7//QfG69q1q7F///5g/+9+9ztDkvGf//mfwb5rrrnGuOSSS0xjNTU1GZdddplx4YUXnnJ8wzAMScbdd99t7N+/38jIyDCWLl1qGIZhvP3224bL5TIqKiqMsrIyQ5Kxd+/e4H4lJSVGp06dDMMwjBdffNGQZLz55pshxz35dzrx3/XTTz81MjMzDUnGgAEDjGnTphkrV640GhoaTjnnlrKgJdOnTzckGX/961+DfV9//bXh8XhMf6OGEf7v/q677jI6duxoeo+vu+46o2fPniHbHj161PD7/aa+AwcOGLm5ucYPfvCDYN+0adOMrKws4+jRoy3O+4EHHjA6depk/N///Z+pf/bs2UZ6erqxc+dOwzAMY+/evYYko6ysrMVjAQCO4/JyAClpxIgRysnJUUFBgW655RZ17txZv/3tb3XOOedIkunbpgMHDqiurk7Dhg3Thx9+eNpjNzU1aeXKlRo9enTwvvETnfyt25QpU0x9w4YN07Fjx/Tll19KOv7tU21trYqLi7Vv377gKz09XUVFRcFLRDMzM5WRkaH3339fBw4ciPi92LNnjzZv3qwJEybozDPPDPZfeuml+ta3vqV33nkn4mNFonPnzrrllluC7T59+ig7O1vf+MY3VFRUFOwP/O8vvvgi2Hfiv8uRI0dUU1OjCy64QNnZ2aZ/m1WrVmnIkCHBb/Ak6cwzz9T48eNNc7H7vT0dt9utiRMnmvreeecd5eXlmdYWaN++ve655x7V19dr3bp1pu3Hjh0rj8cTbAfet9tuu03t2rUz9Tc2Nuqrr76Kas7jxo3TGWecEWwPGzZMUvO/0/79+7V27VrdfPPN8vl8wfe0pqZGI0eO1NatWyOewxlnnKFrr71Wr732mqTj37JfdtllEa2YP378eF144YW6//77w65k3pJ+/fpp8+bNuu2221RRUaGf//znuvHGG5Wbm6tf/epXER/ndN555x1985vfVGFhYbAvJycn5G9UMv/dB97TYcOG6eDBg/rss89OO1Z6enrw6pqmpibt379fR48e1aBBg0z/3WRnZ6uhoUF//OMfWzzWG2+8oWHDhumMM84w/TczYsQIHTt2TP/1X/8V0e8PAGjG5eUAUtLixYvVu3dvtWvXTrm5uerTp4/S0po/Z3zrrbf04IMPavPmzfL7/cH+SC5T3bt3r7xeb4v3nJ6sR48epnagoAkUd1u3bpWkFi91zcrKknS8gHvkkUc0c+ZM5ebm6pvf/Kauv/563XHHHcrLy2tx/EBx36dPn5CffeMb39B7772nhoaGmD3mqnv37iHvo8fjUUFBQUifJFORe+jQIZWXl+v555/XV199ZSqm6urqgv/7yy+/1JAhQ0LGvuCCC0xtu9/b0znnnHNCVub+8ssvdeGFF5r+HqXj/xaBn5/o5L+fwPsWyfvZGqf7e922bZsMw9BPf/pT/fSnPw17jK+//jr4Adfp3Hrrrbr99tu1c+dOrVy5Uo8++mhE+6Wnp+u+++5TSUmJVq5cGfEl7ZLUu3dvLV26VMeOHdM//vEPvfXWW3r00Uc1ZcoUnXfeeTFZhf7LL780fcgUEO6/wy1btui+++7T2rVr5fV6TT878e/+VF588UX97Gc/02effaYjR44E+88777zg//7hD3+o5cuXa9SoUTrnnHP07W9/WzfffLOuvfba4DZbt27VJ598Erxn+2SBxeYAAJGj6AaQkgoLC8N+Cy1J//3f/63vfve7uuKKK/SLX/xCZ599ttq3b6/nn38+ZFGnWEhPTw/bHygoA4sTLV26NGyBd+K3mdOnT9fo0aO1cuVKvffee/rpT3+q8vJyrV27Vv/0T/8U87m3Rku/7+neB+n4/e/PP/+8pk+friFDhsjj8cjlcumWW24JuwDV6ST6vQ13/65V0byfsRzv5L/XWbNmaeTIkWG3PfnDj1P57ne/K7fbrZKSEvn9ft18880R7zt+/Pjgvd2teaxfenq6LrnkEl1yySUaMmSIrrrqKr3yyitxffRbbW2thg8frqysLN1///3BZ4d/+OGH+slPfhLR3/3LL7+sCRMm6MYbb9SPfvQjnXXWWUpPT1d5eXlwPQvp+EJxmzdv1nvvvad3331X7777rp5//nndcccdwYX8mpqa9K1vfUs//vGPw47Vu3fv2PziANCGUHQDaHN+85vfqEOHDnrvvfdMC289//zzIduG++Y7JydHWVlZ+vTTT2Myn8DCW2eddVZEJ/vnn3++Zs6cqZkzZ2rr1q0aMGCAfvazn+nll18Ou33gUt3PP/885GefffaZunXrFrNvuaO1YsUKlZSU6Gc/+1mw7/Dhw6qtrTVt17NnT23bti1k/5P77H5vW6Nnz5765JNP1NTUZPq2O3AZcSSXVkfD6iO2ThZ4lFb79u1jUpxmZmbqxhtv1Msvv6xRo0apW7duEe8b+LZ7woQJ+t3vfhfVPAIf0u3Zsyeq4wT07NkzeKXFiU7+7/D9999XTU2N3nzzTV1xxRXB/sCTFk7U0r/dihUr1KtXL7355pumbcrKykK2zcjI0OjRozV69Gg1NTXphz/8oX75y1/qpz/9qS644AKdf/75qq+vP+2/bbR/RwDQlnBPN4A2Jz09XS6Xy/Q4noqKCq1cuTJk206dOoUUfGlpabrxxhv1n//5n/r73/8eso/VbxpHjhyprKwsPfTQQ6bLQgMCjxc7ePBgyIrO559/vrp06WK6RP5kZ599tgYMGKAXX3zR9Lt8+umn+sMf/qDvfOc7luZrp/T09JD3b9GiRaZ/K+n4e7ZhwwZt3rw52Ld//3698sorIdvZ+d62xne+8x1VVVWZVq8/evSoFi1apM6dOwcf22aXwAcsJ/9dR+qss87SlVdeqV/+8pdhC9Rwj8M7nVmzZqmsrKzFy9VP5bbbbtMFF1yg+fPnR7T9f//3f4f9WwisbRDu8u/W+M53vqONGzfqb3/7W7Bv7969IX+jgSsLTvy7b2xs1C9+8YuQY3bq1Cns5ebhjvHXv/5VGzZsMG1XU1NjaqelpQVXHA/8nd98883asGGD3nvvvZBxamtrdfToUUkKPkmgtX9HANCW8E03gDbnuuuu0+OPP65rr71Wt956q77++mstXrxYF1xwgT755BPTtgMHDtTq1av1+OOPKz8/X+edd56Kior00EMP6Q9/+IOGDx+uKVOm6Bvf+Ib27NmjN954Q3/+85+VnZ0d8XyysrK0ZMkS3X777frnf/5n3XLLLcrJydHOnTv19ttv6/LLL9dTTz2l//u//9M111yjm2++WRdddJHatWun3/72t6qurjYtXBbOggULNGrUKA0ZMkSTJk0KPjLM4/Ek1bN1r7/+ei1dulQej0cXXXSRNmzYoNWrVwcf9Rbw4x//WC+//LK+9a1vaerUqcFHhvXo0UP79+8PfgsXj/fWqilTpuiXv/ylJkyYoE2bNuncc8/VihUr9Je//EULFy4MPj7NLgMHDpQk3XPPPRo5cqTS09Mt/46LFy/W0KFDdckll2jy5Mnq1auXqqurtWHDBu3atUsff/yxpeP1799f/fv3t7RPQHp6uu69996QBeta8sgjj2jTpk363ve+Fyw4P/zwQ7300ks688wzNX369FbN42Q//vGPtXTpUl177bWaNm1a8JFhgSsdAi677DKdccYZKikp0T333COXy6WlS5eG/fBu4MCBev311zVjxgwNHjxYnTt31ujRo3X99dfrzTff1JgxY3Tddddpx44devrpp3XRRRepvr4+uP+dd96p/fv36+qrr1b37t315ZdfatGiRRowYEBwTYEf/ehH+v3vf6/rr79eEyZM0MCBA9XQ0KD/+Z//0YoVK1RRUaFu3bopMzNTF110kV5//XX17t1bZ555pi6++OKI17oAgDYlMYumA4A9Wnp808meffZZ48ILLzTcbrfRt29f4/nnnw8+ouhEn332mXHFFVcEHzF04iODvvzyS+OOO+4wcnJyDLfbbfTq1cu4++67g4/uaWku4R61FegfOXKk4fF4jA4dOhjnn3++MWHCBOPvf/+7YRiGsW/fPuPuu+82+vbta3Tq1MnweDxGUVGRsXz58ojem9WrVxuXX365kZmZaWRlZRmjR482/vGPf4SdWzSPDOvXr1/Itj179jSuu+66kH6d9IinAwcOGBMnTjS6detmdO7c2Rg5cqTx2WefGT179gx5XNNHH31kDBs2zHC73Ub37t2N8vJy48knnzQkGVVVVSFzteu9PdUjw8K9F4ZhGNXV1cHfMyMjw7jkkktMj04zjPCPuwr8LuH+jSL92z969KgxdepUIycnx3C5XMG/+ZbGMwwj7KOhtm/fbtxxxx1GXl6e0b59e+Occ84xrr/+emPFihWnHD9wvBP/3cM53SPDTnTkyBHj/PPPj+iRYX/5y1+Mu+++27j44osNj8djtG/f3ujRo4cxYcIEY/v27S3Ox+ojwwzDMD755BNj+PDhRocOHYxzzjnHeOCBB4xnn3025JFhf/nLX4xvfvObRmZmppGfn2/8+Mc/Dj5S78T/vurr641bb73VyM7ONiQFHx/W1NRkPPTQQ0bPnj0Nt9tt/NM//ZPx1ltvGSUlJaZHjK1YscL49re/bZx11llGRkaG0aNHD+Ouu+4y9uzZY5q3z+cz5syZY1xwwQVGRkaG0a1bN+Oyyy4zHnvsMaOxsTG43fr1642BAwcaGRkZPD4MAE7BZRhRrrgCAECSmD59un75y1+qvr6+xQXBAAAA4ol7ugEAjnTo0CFTu6amRkuXLtXQoUMpuAEAQNLgnm4AgCMNGTJEV155pb7xjW+ourpazz77rLxeb6sW4wIAALALRTcAwJG+853vaMWKFXrmmWfkcrn0z//8z3r22WdNj10CAABINO7pBgAAAADAJtzTDQAAAACATSi6AQAAAACwCUU3AAAAAAA2oegGAAAAAMAmFN0AAAAAANiEohsAAAAAAJtQdAMAAAAAYBOKbgAAAAAAbELRDQAAAACATSi6AQAAAACwCUU3AAAAAAA2oegGAAAAAMAmFN0AAAAAANiEohsAAAAAAJtQdAMAAAAAYBOKbgAAAAAAbELRDQAAAACATSi6AQAAAACwCUU3AAAAAAA2oegGAAAAAMAmFN0AAAAAANiEohsAAAAAAJtQdAMAAAAAYBOKbgAAAAAAbELRDQAAAACATSi6AQAAAACwCUU3AAAAAAA2oegGAAAAAMAmFN0AAAAAANikXWt2Wrx4sRYsWKCqqir1799fixYtUmFh4Wn3a2pq0u7du9WlSxe5XK7WDG07wzDk8/mUn5+vtDQ+kwBSSWuzSyK/ACQO2QXAqagbmze2ZNmyZUZGRobx3HPPGVu2bDEmT55sZGdnG9XV1afdt7Ky0pDkiFdlZaXVtwZAEosmuwyD/AKQGGQXAKeibmzmMgzDkAVFRUUaPHiwnnrqKUnHP4UoKCjQ1KlTNXv27FPuW1dXp+zsbCvDJUxtba08Hk+ipwEgRqLJLon8ApAYZBcAp6JubGbpGp7GxkZt2rRJI0aMaD5AWppGjBihDRs2hGzv9/vl9XqDL5/PZ2W4hErWyxgAWGc1uyTyC0DikV0AnIq60cxS0b1v3z4dO3ZMubm5pv7c3FxVVVWFbF9eXi6PxxN8FRQUWBkOAGLCanZJ5BeAxCO7ADgVdaOZratVzJkzR3V1dcFXZWWlncMBQMyQXwCciOwC4ESpnl2WVi/v1q2b0tPTVV1dbeqvrq5WXl5eyPZut1tutzuk/yc/+Ympv2PHjiHb9OnTJ6Tv7rvvDul77LHHws61uLg4pO/w4cMhfQ8//LCp7ff7Q/oAOJvV7JJazq958+apQ4cOwXY0WRUup6TIskqS5s+fH3Z/AKkhltn1yiuvmM63osmpcBklkVMAmsWqbszLyzOtDB5NTrVU48Ujpyx9052RkaGBAwdqzZo1wb6mpiatWbNGQ4YMifnkACAWyC4ATkR2AXAq8svM8nO6Z8yYoZKSEg0aNEiFhYVauHChGhoaNHHiRDvmBwAxQXYBcCKyC4BTkV/NLBfd48aN0969ezV37lxVVVVpwIABWrVqVchN8gCQTMguAE5EdgFwKvKrmeWiW5JKS0tVWloa67kAgK3ILgBORHYBcCry67hWFd3Rmj17trKysk65za5du0L6nnzyyZC+MWPGhN0/3LPdPv7445C+devWmdpHjx495bwAtG3Tpk0z5Vc0WdXSMygjySoAsKJ///7q0qVLsB1NToXLKImcAhB7jz76qGkRyGhyKpEZZesjwwAAAAAAaMsougEAAAAAsAlFNwAAAAAANqHoBgAAAADAJi7DMIx4Deb1euXxeHTgwAHTQkRNTU0h2/7gBz8I6auvr494rD179oT0HThwIKTv888/D7t/XV3daRd7A9B2BPKrpqbGlA3RZFW4nJKsZVU45BeAgEB2jRs3ThkZGcH+aHIqXEZJ1nIqHLILQEAgu66//nq1b9/+lNtGW/dFK5Ls4ptuAAAAAABsQtENAAAAAIBNKLoBAAAAALAJRTcAAAAAADZJyEJq1dXVppvNGxsbQ7b1eDzxmlZYLOYB4ESB/KqsrDRlQ6KzKhzyC0BAILucgOwCEJBq2cU33QAAAAAA2ISiGwAAAAAAm1B0AwAAAABgE4puAAAAAABsYqnonjdvnlwul+nVt29fu+YGADFBdgFwKvILgBORXWbtrO7Qr18/rV69uvkA7SwfQsOHD1d6enqwPW3aNMvHAAArYpFdkvTmm28qMzMzVtMCgNOKVX4BQDyRXc0s/+bt2rVTXl5eRNv6/X75/f5g2+v1Wh0OAGLCSnZJ5BeA5MG5FwAnIruaWb6ne+vWrcrPz1evXr00fvx47dy5s8Vty8vL5fF4gq+CgoKoJgsArWUluyTyC0Dy4NwLgBORXc1chmEYkW787rvvqr6+Xn369NGePXs0f/58ffXVV/r000/VpUuXkO3DfWJRUFCgvn37nvby8ilTplj9XWIqkoecA3AGq9kltZxfP//5z02Xlyc6q8Ihv4DUEatzLycgu4DUQXaZWbq8fNSoUcH/femll6qoqEg9e/bU8uXLNWnSpJDt3W633G63lSEAIOasZpdEfgFIDpx7AXAissssqrvZs7Oz1bt3b23bts3Sfp999pmpnYzfFAFIXa3NLomFHwEkVjT5BQCJ0tazK6rndNfX12v79u06++yzYzUfALAd2QXAqcgvAE7U1rPLUtE9a9YsrVu3ThUVFVq/fr3GjBmj9PR0FRcX2zU/AIga2QXAqcgvAE5EdplZurx8165dKi4uVk1NjXJycjR06FBt3LhROTk5ds0PAKJGdgFwKvILgBORXWaWVi+PltfrlcfjiddwUWEFTQAnIr8AOBHZBcCJUi27orqnGwAAAAAAtIyiGwAAAAAAm1B0AwAAAABgE4puAAAAAABsEteiO45rtkXNSXMFYD8nZYKT5grAXk7KAyfNFYC9nJQHkcw1rkW3z+eL53BRcdJcAdjPSZngpLkCsJeT8sBJcwVgLyflQSRzjesjw5qamrR792516dJFPp9PBQUFqqystPXxEF6v19I4hmHI5/MpPz9faWlcfQ/guEB+GYahHj16JF12SeQXgFDxPvciuwDEQqplV7tYTDJSaWlp6t69uyTJ5XJJkrKysuLyTEYr4zjlmXAA4ieQX16vV1JyZpdEfgEwS9S5F9kFIBqpll18nAgAAAAAgE0ougEAAAAAsEnCim63262ysjK53e6UGAdA20B2AXCqeOQK2QUg1lIhu+K6kBoAAAAAAG1JqxZSW7x4sRYsWKCqqir1799fixYtUmFh4Wn3O3EVusAN8cmGFTSB1NXa7JLILwCJQ3YBcCrqxuaNLVm2bJmRkZFhPPfcc8aWLVuMyZMnG9nZ2UZ1dfVp962srDQkOeJVWVlp9a0BkMSiyS7DIL8AJAbZBcCpqBubWb68vKioSIMHD9ZTTz0l6finEAUFBZo6dapmz559yn3r6uqUnZ1tZbiEqa2t5fEVQAqJJrsk8gtAYpBdAJyKurGZpWt4GhsbtWnTJo0YMaL5AGlpGjFihDZs2BCyvd/vl9frDb58Pp+V4RIqWS9jAGCd1eySyC8AiUd2AXAq6kYzS0X3vn37dOzYMeXm5pr6c3NzVVVVFbJ9eXm5PB5P8FVQUGBlOACICavZJZFfABKP7ALgVNSNZrauVjFnzhzV1dUFX5WVlXYOBwAxQ34BcCKyC4ATpXp2WVq9vFu3bkpPT1d1dbWpv7q6Wnl5eSHbu93usM86+/Wvf62OHTsG28XFxSHbHD58OKTv4YcfDumbP39+RHMH0HZZzS6p5fwCgHhJ1ew699xzTe2mpibt3LkzMZMBYItY1Y2J0qNHj5C+jIwMU7upqUlffPFFRMez9E13RkaGBg4cqDVr1pgGW7NmjYYMGWLlUAAQN2QXACciuwA4FfllZvk53TNmzFBJSYkGDRqkwsJCLVy4UA0NDZo4caId8wOAmIg2uxobG22eIQCEIrsAOFU0+ZVq2WW56B43bpz27t2ruXPnqqqqSgMGDNCqVatCbpIHgGQSbXbV1NTYPEMACEV2AXCqaPIr1bLLctEtSaWlpSotLY31XADAVmQXACciuwA4Ffl1XKuK7mjddNNNysrKCrbDPYft448/Dulbt26drfMCgJZ07do10VMIYRiGqe31euXxeBI0GwDJKNHZNWjQoJC+Dz74wNQmuwCcLJ7ZNWDAgJC+999/P6Tv5Jyykl22PjIMAFLFyStWAoATkF0AnCjVsouiGwAAAAAAm1B0AwAAAABgE4puAAAAAABskpCF1G6//Xa1b98+2N6zZ0/INgcOHAjp+/zzz22dFwA4SUlJiamdas+0BOB8O3bsCOnbt2+fqR1uQV0AiJedO3eG9IV7ZFk0Cz7yTTcAAAAAADah6AYAAAAAwCYU3QAAAAAA2ISiGwAAAAAAmyRkIbW33norEcMCQEp56aWXEj0FADilcIsR3X333ab2kSNH4jUdAAixf//+kL6ZM2eG9I0ePdrUPnToUMRj8E03AAAAAAA2oegGAAAAAMAmFN0AAAAAANiEohsAAAAAAJtYKrrnzZsnl8tlevXt29euuQFATJBdAJyK/ALgRGSXmeXVy/v166fVq1c3H6BdQhZABwBLyC4ATpVq+bV8+fJETwFAHDg5u1auXBnSt3btWlPbMIyIj2f5N2/Xrp3y8vKs7gYACUV2AXAq8guAE5FdzSzf071161bl5+erV69eGj9+vHbu3Nnitn6/X16v1/QCgESwkl0S+QUgeXDuBcCJyK5mloruoqIivfDCC1q1apWWLFmiHTt2aNiwYfL5fGG3Ly8vl8fjCb4KCgpiMmkAsMJqdknkF4DkwLkXACciu8xchpWL0U9SW1urnj176vHHH9ekSZNCfu73++X3+4Ntr9frmDewrq5OWVlZiZ4GABucLrsk8gtAcuLcC4ATpUJ2nZxPhmHI5/NFlF1R3c2enZ2t3r17a9u2bWF/7na75Xa7oxkCAGLudNklkV8AkhPnXgCcKBWyK5pL3qN6Tnd9fb22b9+us88+O5rDAEBckV0AnIr8AuBEbT27LBXds2bN0rp161RRUaH169drzJgxSk9PV3FxsV3zA4CokV0AnIr8AuBEZJeZpcvLd+3apeLiYtXU1CgnJ0dDhw7Vxo0blZOTY9f8ACBqZBcApyK/ADgR2WUW1UJqVnm9Xnk8nngNFxUW8wBwIvILgBORXQCcKNWyK6p7ugEAAAAAQMsougEAAAAAsAlFNwAAAAAANqHoBgAAAADAJnEtuuO4ZlvUnDRXAPZzUiY4aa4A7OWkPHDSXAHYy0l5EMlc41p0+3y+eA4XFSfNFYD9nJQJTporAHs5KQ+cNFcA9nJSHkQy17g+MqypqUm7d+9Wly5d5PP5VFBQoMrKSlsfD+H1ei2NYxiGfD6f8vPzlZbG1fcAjgvkl2EY6tGjR9Jll0R+AQgV73MvsgtALKRadrWLxSQjlZaWpu7du0uSXC6XJCkrKysuz2S0Mo5TngkHIH4C+eX1eiUlZ3ZJ5BcAs0Sde5FdAKKRatnFx4kAAAAAANiEohsAAAAAAJskrOh2u90qKyuT2+1OiXEAtA1kFwCnikeukF0AYi0VsiuuC6kBAAAAANCWtOqb7sWLF+vcc89Vhw4dVFRUpL/97W+xnhcAxBzZBcCJyC4ATkV+HWf5m+7XX39dd9xxh55++mkVFRVp4cKFeuONN/T555/rrLPOOuW+Jy79HliFLtnw2AogNUWTXRL5BSAxyC4ATkXd2Mxy0V1UVKTBgwfrqaeeknT8DSkoKNDUqVM1e/bsU+67a9cuFRQUWBkuYSorK4PL1ANwvmiySyK/ACQG2QXAqagbm1n6OLGxsVGbNm3SiBEjmg+QlqYRI0Zow4YNIdv7/X55vd7gy0m3j3fp0iXRUwAQI1azSyK/ACReqmZXWlqa6RX4FovsAlKH0+vGk3MqLS1NZ5xxhumVnZ0tKbLsslR079u3T8eOHVNubq6pPzc3V1VVVSHbl5eXy+PxBF89evSwMlxCJetlDACss5pdEvkFIPFSNbtcLlfIK9APIDU4vW4Ml1PRZJetN87MmTNHdXV1wVdlZaWdwwFAzJBfAJyI7ALgRKmeXe2sbNytWzelp6erurra1F9dXa28vLyQ7d1uN89pBJBwVrNLIr8AJB7ZBcCpqBvNLBXdGRkZGjhwoNasWaMbb7xR0vEb4tesWaPS0lI75tdq4S5JyMjICOm7/PLLTe3Gxka99tprts0LQPwla3a1dOlUJFklSUOHDjW1Dx06pHvuuSc2kwOQcMmQXZGeT0mR5ZQknXHGGab2wYMHdccdd7RyhgCSUTzzq7V1X0AkOSVJN910k6nt9Xrl8XgimqOloluSZsyYoZKSEg0aNEiFhYVauHChGhoaNHHiRKuHAoC4iTa7GhsbbZ4hAIQiuwA4VTT5lWrZZbnoHjdunPbu3au5c+eqqqpKAwYM0KpVq0JukgeAZBJtdtXU1Ng8QwAIRXYBcKpo8ivVssty0S1JpaWlSXc5OQCcDtkFwInILgBORX4dZ+vq5QCQKrp27ZroKQCAZWQXACdKtexq1TfdyWTAgAFh+99///2QvkhudPd6vSykBiBESwsHRSpcVoXLKSmyrArH6/WykBoAEyvZFWlOtTajWuL1emN6PADO11J2JSqnosU33QAAAAAA2ISiGwAAAAAAm1B0AwAAAABgE4puAAAAAABs4viF1Hbu3Bm2P9yz3ZLthnoAbUe4rGrpGZRkFYBEiDSnyCgAieLUnOKbbgAAAAAAbELRDQAAAACATSi6AQAAAACwCUU3AAAAAAA2cfxCavv37w/bP3PmzJC+0aNHh/R99NFHpnZjY2NsJgYAJwiXVeFySoosqyRp0aJF0U8MAP6/SHMqXEZJ5BQA+0WTU+EySoo8pzZv3mxq19fXR7SfxDfdAAAAAADYhqIbAAAAAACbUHQDAAAAAGATS0X3vHnz5HK5TK++ffvaNTcAiAmyC4BTkV8AnIjsMrO8kFq/fv20evXq5gO0c/xabADaALILgFORXwCciOxqZvk3b9eunfLy8uyYS0ytXLkypG/t2rUhfT6fz9Q2DMOuKQFIoGTMrnA5JUWWVZLUv39/U/vQoUMxmReA5JLI/Ir0fEqKLKck6c4774x6XgCSX7yyq7V1X0CkOfXYY4+Z2keOHIlwhq24p3vr1q3Kz89Xr169NH78eO3cubPFbf1+v7xer+kFAIlgJbsk8gtA8uDcC4ATkV3NLBXdRUVFeuGFF7Rq1SotWbJEO3bs0LBhw1r81KC8vFwejyf4KigoiMmkAcAKq9klkV8AkgPnXgCciOwycxlRXE9dW1urnj176vHHH9ekSZNCfu73++X3+4Ntr9eb0DcwKysrpK+ly8vr6urCbg/A+U6XXVJi8yuSrJKkZ555xtQ+dOiQ7rnnHvILSGHJcO7VUr5EklNS6GWbXq9XHo+H7AJSWLyzK9JzKSmynJKk2267zdQ+cuSIli9fHlF2RXU3e3Z2tnr37q1t27aF/bnb7Zbb7Y5mCACIudNll0R+AUhOnHsBcKK2nl1RFd319fXavn27br/99ljNx1apdm8AgNZJ9uyKNKvq6upM7cOHD9sxHQBJJBnyy8r51Mk5BaBtind22ZFTkydPNrUbGhq0fPnyiPa1dE/3rFmztG7dOlVUVGj9+vUaM2aM0tPTVVxcbOUwABBXZBcApyK/ADgR2WVm6ZvuXbt2qbi4WDU1NcrJydHQoUO1ceNG5eTk2DU/AIga2QXAqcgvAE5EdplZKrqXLVtm1zwAwDZkFwCnIr8AOBHZZWb5Od0AAAAAACAyUS2kBgBInLKyMlM7iidAAoAtTs4pSRo0aJCp3dDQEK/pAECISHJKkoYPH25qW1msjW+6AQAAAACwCUU3AAAAAAA2oegGAAAAAMAmcb2n20n3GzpprgDsl4yZcPKcAu1knCuAxEh0HoQb/+R7uA8ePNjitgDapnjmQSQ5JYXewx1oRzLXuBbdPp8vnsNFxefzyePxJHoaAJJEMuZX4ET1ZOQXgIBEZ1e4nLruuuvCbkt2AQiIZ3ZZyalwIskulxHHjxGampq0e/dudenSRT6fTwUFBaqsrFRWVpZtY3q9XkvjGIYhn8+n/Px8paVx9T2A4wL5ZRiGevTokXTZJZFfAELF+9yL7AIQC6mWXXH9pjstLU3du3eXJLlcLklSVlaWrSeuAVbG4VNWACcL5FfgUqJkzC6J/AJglqhzL7ILQDRSLbv4OBEAAAAAAJtQdAMAAAAAYJOEFd1ut1tlZWVyu90pMQ6AtoHsAuBU8cgVsgtArKVCdsV1ITUAAAAAANqSVi2ktnjxYi1YsEBVVVXq37+/Fi1apMLCwtPud+IqdIEb4pMNK2gCqau12SWRXwASh+wC4FTUjc0bW7Js2TIjIyPDeO6554wtW7YYkydPNrKzs43q6urT7ltZWWlIcsSrsrLS6lsDIIlFk12GQX4BSAyyC4BTUTc2s3x5eVFRkQYPHqynnnpK0vFPIQoKCjR16lTNnj3btK3f75ff7w+26+rq1KNHDyvDtVq4TxsiWdLdMAzV1taqtraWx1cAKcRKdknxya+WPhVtbfaQX0DqSXR2tfZ86lTuuusuU9vv9+uJJ54gu4AUE6+6MR45JUmZmZmm9uHDh1VeXh5Rdlm6hqexsVGbNm3SiBEjmg+QlqYRI0Zow4YNIduXl5fL4/EEX/EquKXjz3Nr7SuwP4DUYDW7pPjkVzQ5RX4BqS8ZssuOnHK73SGvwFgAUkM868Z45VSHDh1CXoHxT8dS0b1v3z4dO3ZMubm5pv7c3FxVVVWFbD9nzhzV1dUFX5WVlVaGA4CYsJpdEvkFIPHILgBORd1o1qqF1CJ14qeXAOAk5BcAJyK7ADhRqmeXpaK7W7duSk9PV3V1tam/urpaeXl5rZ5EuMsHMjIyQvouv/zykL6hQ4eGPeYZZ5wR0nfTTTeddi5er5f7iYAUE8vs6t69u+neoWiyKlxOSZFlVTjkF5BaYpldvXr1MmVXNDnV2oxqidfr1cMPPxzTYwJIrFjlV3FxselcK1E5FY7X61VZWVlE21q6vDwjI0MDBw7UmjVrgn1NTU1as2aNhgwZYm2WABAnsciuxsZGu6YHAGGRXQCcKtr8SrXssnx5+YwZM1RSUqJBgwapsLBQCxcuVENDgyZOnGjH/AAgJqLNrpqaGptnCAChyC4AThVNfqVadlkuuseNG6e9e/dq7ty5qqqq0oABA7Rq1aqQm+QBIJmQXQCciOwC4FTkV7NWLaRWWlqq0tLSWM8FAGwVTXZ17do1xrMBgMiQXQCcqrX5lWrZZevq5S255JJLlJ6eHmy///77IduwGBCAZBJYxGP9+vXKysoK9pNVAJJZILs++ugjU3YBQDILZNfTTz+dNNnV1NR0yvapWFpIDQAAAAAARI6iGwAAAAAAm1B0AwAAAABgE4puAAAAAABskpCF1Hbt2iWXyxVsh3sOW7wWJ/rrX/9qajc0NMRlXADOtH//fh05ciTYTlRWSVJtba2pTX4BSKRIckqSrrrqKlO7sbHRrikBQFC4jJIiyykpNKsOHjwY8dh80w0AAAAAgE0ougEAAAAAsAlFNwAAAAAANqHoBgAAAADAJglZSO3AgQOm9syZM0O2GT16dEjfRx99FNK3aNGiiMfdvHlzSN8111xjahuGEfHxALQ99957r9q3bx9sJyqrJBZOAxC5pUuXKjMzM9iOJqfCZZQUeU7169fP1D527FhE4wJoe370ox8pIyMj2I4mp8JllBRZTknS9OnTTe1Dhw5FNBeJb7oBAAAAALANRTcAAAAAADah6AYAAAAAwCaWiu558+bJ5XKZXn379rVrbgAQE2QXAKcivwA4EdllZnkhtX79+mn16tXNB2iXkLXYAMASsguAU5FfAJyI7Gpm+Tdv166d8vLyYjqJlStXhvStXbs2pM/n84X09e/fP+wx77zzzpC+xx57LKSP1X+BtiFW2fX222+b2tFkVbicksgqAGaxyK85c+bI5XIF29HkVLiMkiLPqS1btkS0HQBni0V2PfPMM6bsiianrJxLhcupyZMnR7z/ySzf071161bl5+erV69eGj9+vHbu3Nnitn6/X16v1/QCgESwkl0S+QUgeXDuBcCJyK5mloruoqIivfDCC1q1apWWLFmiHTt2aNiwYWE/LZWk8vJyeTye4KugoCAmkwYAK6xml0R+AUgOnHsBcCKyy8xS0T1q1CiNHTtWl156qUaOHKl33nlHtbW1Wr58edjt58yZo7q6uuCrsrIyJpMGACusZpdEfgFIDpx7AXAissssqrvZs7Oz1bt3b23bti3sz91ut9xudzRDAEDMnS67JPILQHLi3AuAE7X17Iqq6K6vr9f27dt1++23x2o+QZFex19XVxfxMcPd/P7aa6+Z2oZhyDCMiI8JwHlimV2JyipJampqiviYAFJDa/PrVLfTBESaUy0tJkROAWhJNOdeJ9Zm0eRUuIyS4pNTli4vnzVrltatW6eKigqtX79eY8aMUXp6uoqLi+2aHwBEjewC4FTkFwAnIrvMLH3TvWvXLhUXF6umpkY5OTkaOnSoNm7cqJycHLvmBwBRI7sAOBX5BcCJyC4zS0X3smXL7JoHANiG7ALgVOQXACciu8wsP6cbAAAAAABExmXEcdUwr9crj8cT02N26tQpbP/bb78d0jd8+PCQvpEjR5raR48e1dq1a1VXV6esrKzYTBKA40WbX+GyKlxOSZFllST94Q9/CLs/+QUgwEp2RZpT4TJKspZT4ZBdAAJayq5ocipcRknWciqcSLKLb7oBAAAAALAJRTcAAAAAADah6AYAAAAAwCaWVi+Plh23j7d0zIaGhpA+r9cb0nf06NGw7Tje6g7AAaLNhHD7h8spKbKssjoWgLbJSh5EmlPhMkqyllORjg+gbWopD6LJqWgzqiWRZFdcF1LbtWuXCgoK4jVcVCorK9W9e/dETwNAkiC/ADgR2QXAiVItu+JadDc1NWn37t3q0qWLfD6fCgoKVFlZaetKlV6v19I4hmHI5/MpPz9faWlcfQ/guEB+GYahHj16JF12SeQXgFDxPvciuwDEQqplV1wvL09LSwt+CuByuSRJWVlZcXk8hJVxYv1YMwDOF8ivwOVKyZhdEvkFwCxR515kF4BopFp28XEiAAAAAAA2oegGAAAAAMAmCSu63W63ysrK5Ha7U2IcAG0D2QXAqeKRK2QXgFhLheyK60JqAAAAAAC0Ja1aSG3x4sVasGCBqqqq1L9/fy1atEiFhYWn3e/EVegCN8QnG1bQBFJXa7NLIr8AJA7ZBcCpqBubN7Zk2bJlRkZGhvHcc88ZW7ZsMSZPnmxkZ2cb1dXVp923srLSkOSIV2VlpdW3BkASiya7DIP8ApAYZBcAp6JubGb58vKioiINHjxYTz31lKTjn0IUFBRo6tSpmj17tmlbv98vv98fbNfV1alHjx4hxwz3yUC0j4646667QvoyMzND+nr37m1qHzx4UJMmTVJtbS2PrwBSiJXsklrOL5fLZfrENZqcCJdTUmRZJUn/9m//Zmo3NTXp66+/Jr+AFBKr7MrOzm7Vt0WRnk9JkeWUJP3Hf/yHqX3o0CGVlpaSXUCKiUXdGEl2TZkyJaQvXE5deOGFYfefOXNmSN+DDz4Y0jd27FhTO/Bs70iyy9Ll5Y2Njdq0aZPmzJkT7EtLS9OIESO0YcOGkO3Ly8s1f/780x433BsZ7WUE4W6C79ChQ0hfx44dI54TAGeyml1Sy/l1ctEdTVa0tFhHpFnV0qVM5BeQGuzMrkhFej4lRZ5TnHsBqS9WdWMk2RVt3RdpTrX0/O5IssvSjTP79u3TsWPHlJuba+rPzc1VVVVVyPZz5sxRXV1d8FVZWWllOACICavZJZFfABKP7ALgVNSNZq1aSC1SbrebR0YAcCTyC4ATkV0AnCjVs8tS0d2tWzelp6erurra1F9dXa28vLyIj/Pkk0+arrM/44wzQra56aabrEyt1Xbt2mVq+3y+uIwLIH5ilV2S9MILL5guOUpUVkkK3iMVcPDgQd12221xmQ8A+8UyuyoqKlq8NDJWIskpSRozZoyp7fV6NWnSJNvmBSD+YpVfX3zxRcyyK1xGScdr05OdnFNSaJ1opW60dHl5RkaGBg4cqDVr1gT7mpqatGbNGg0ZMsTKoQAgbmKRXY2NjXZNDwDCIrsAOFW0+ZVq2WX58vIZM2aopKREgwYNUmFhoRYuXKiGhgZNnDjRjvkBQExEm101NTU2zxAAQpFdAJwqmvxKteyyXHSPGzdOe/fu1dy5c1VVVaUBAwZo1apVITfJA0AyIbsAOBHZBcCpyK9mrVpIrbS0VKWlpbGeCwDYKprs6tq1a4xnAwCRIbsAOFVr8yvVssvW1ctbUlJSYvtiHuE0NTWF9N17772mdqrdPwAgNjIyMiRJN9xwg+35FUlWSaELeBw5csS2OQFwpkB2xVK4jJIiyylJWrp0qalNdgE4WbTZFS6n7rvvvrDb1tfXh/S98sorIX179uwxtY8ePRrxfCwtpAYAAAAAACJH0Q0AAAAAgE0ougEAAAAAsAlFNwAAAAAANknIQmqt9de//jWkr7a2Nuy2V111VUhfuEXSXnrppajnBQAnijSrwuWURFYBsF80OdXSorPkFIBY+/vf/65OnToF29Hk1MmLOMYT33QDAAAAAGATim4AAAAAAGxC0Q0AAAAAgE0ougEAAAAAsEnSLqS2efPmkL5rrrkmpK+hoSHs/v369Qvpmz59erTTAgCTaLIqXE5JZBWA2Pvkk0/UuXPnYDuanCKjAMTLDTfcIJfLFWxHmlPTpk2zdV5W8U03AAAAAAA2oegGAAAAAMAmFN0AAAAAANjEUtE9b948uVwu06tv3752zQ0AYoLsAuBU5BcAJyK7zCwvpNavXz+tXr26+QDtknYtNgAIIrsAOBX5BcCJyK5mln/zdu3aKS8vL6pBX3zxRWVmZgbbd955Z8g2jz32WEhfSyuVh7Nly5aQvsmTJ0e8P4DUEovsCiearAqXUxJZBcAsFvm1aNEitW/fPtiOJqfIKACRiEV2HTx48LTbhMupKVOmRDVurFm+p3vr1q3Kz89Xr169NH78eO3cubPFbf1+v7xer+kFAIlgJbsk8gtA8uDcC4ATkV3NLBXdRUVFeuGFF7Rq1SotWbJEO3bs0LBhw+Tz+cJuX15eLo/HE3wVFBTEZNIAYIXV7JLILwDJgXMvAE5Edpm5DMMwWrtzbW2tevbsqccff1yTJk0K+bnf75ff7w+2vV6vCgoK9OSTT5728vLbbrstpO+VV15p7VQtq6urU1ZWVtzGAxA/p8suqeX8OjkbEp1V4ZBfQOpq7bnXzTffbLq8PNE5FQ7ZBaSu1maXE0SSXVHdzZ6dna3evXtr27ZtYX/udrvldrujGQIAYu502SWRXwCSE+deAJyorWdXVEV3fX29tm/frttvv93Sfl6vV42NjafcJtwiHa+99lpIX1NTk6WxAaC12RUOWQUgnlqbXyUlJerUqVOwTU4BiKfWZlfgcWMBTs0pS/d0z5o1S+vWrVNFRYXWr1+vMWPGKD09XcXFxXbNDwCiRnYBcCryC4ATkV1mlr7p3rVrl4qLi1VTU6OcnBwNHTpUGzduVE5Ojl3zA4CokV0AnIr8AuBEZJeZpaJ72bJlds0DAGxDdgFwKvILgBORXWaWn9MNAAAAAAAiE9VCaq310EMPmW6IHzRoUMg2w4cPD+kbMWJESN8f/vCH2E4OAE7hz3/+s2kxIrIKgBMMHTrU9EgbcgqAE1x11VVq1665ZHVqTvFNNwAAAAAANqHoBgAAAADAJhTdAAAAAADYJK73dBuGYfq/AQ0NDSHber3ekL6jR4/aM7EwTp4jgLYtkAkHDx409Sc6q8IhvwAEBPLg5KxKdE6FQ3YBCAjkQTJm1ckiya64Ft0+n0+SdOjQIVP/ddddF89pRMTn88nj8SR6GgCSRCC/xo4dm+CZnB75BSAgkF0FBQUJnsnpkV0AAgLZ9V//9V8JnsnpRZJdLiOOHys2NTVp9+7d6tKli3w+nwoKClRZWWlaTTPWvF6vpXEMw5DP51N+fr7S0rj6HsBxgfwyDEM9evRIuuySyC8AoeJ97kV2AYiFVMuuuH7TnZaWpu7du0tS8JFhWVlZtp64BlgZh09ZAZwskF+BSzSTMbsk8guAWaLOvcguANFItezi40QAAAAAAGxC0Q0AAAAAgE0SVnS73W6VlZXJ7XanxDgA2gayC4BTxSNXyC4AsZYK2RXXhdQAAAAAAGhLWrWQ2uLFi7VgwQJVVVWpf//+WrRokQoLC0+734mr0AVuiE82rKAJpK7WZpdEfgFIHLILgFNRNzZvbMmyZcuMjIwM47nnnjO2bNliTJ482cjOzjaqq6tPu29lZaUhyRGvyspKq28NgCQWTXYZBvkFIDHILgBORd3YzPLl5UVFRRo8eLCeeuopScc/hSgoKNDUqVM1e/bsU+5bV1en7OxsZWdnmz6xmDJlSsi2mZmZIX0XXnhhSN/MmTPDjvXggw+G9I0dOzak7/Dhw6a2z+fTBRdcoNraWh5fAaSQaLJLas6v6dOnm+73iSarwuWUFFlWSdITTzxhavv9fj3xxBPkF5BCYpVds2fPVocOHYL90eRUuIySIsspSXr44YfD7k92AaklFnXjr371K3Xs2DHYH01OhcsoyVpOhRNJdlm6vLyxsVGbNm3SnDlzgn1paWkaMWKENmzYELK93++X3+8Ptn0+n6Tjz1o7segOd8P6if+PIeDEN/zE8cMJt224Z65lZGSE3T9ZL2MAYJ3V7JJazi+3223KrGiyKtx2UuRZ1dJiH+QXkBpimV0dOnQw5VU0OdXSM2yt5FQ4ZBeQOmJVN3bs2NGUQ9HkVEt1X7SLp0WSXZZunNm3b5+OHTum3NxcU39ubq6qqqpCti8vL5fH4wm+CgoKrAwHADFhNbsk8gtA4pFdAJyKutHM1tUq5syZo7q6uuCrsrLSzuEAIGbILwBORHYBcKJUzy5Ll5d369ZN6enpqq6uNvVXV1crLy8vZPuTL8MM+OKLL1q8NOlUdu3aFdL35JNPht12zJgxIX2ByxRO9PHHH5vaDQ0NlucFILlZzS6p5fyaPXv2afMr0qwKl1NSZFklSevWrTO1jx49esp5AXCWWGbXtGnTTNkVTU6FyygpspwC0DbEqm7s37+/unTpEmxHk1PhMkqKT05Z+qY7IyNDAwcO1Jo1a4J9TU1NWrNmjYYMGRLzyQFALMQiuxobG+2aHgCERXYBcKpo8yvVssvyc7pnzJihkpISDRo0SIWFhVq4cKEaGho0ceJEO+YHADERbXbV1NTYPEMACEV2AXCqaPIr1bLLctE9btw47d27V3PnzlVVVZUGDBigVatWhdwkDwDJhOwC4ERkFwCnIr+aWS66Jam0tFSlpaWxngsA2Cqa7OratWuMZwMAkSG7ADhVa/Mr1bLLZRiGEa/BvF6vPB6PDhw4cNqFiJqamkL6fvCDH4T01dfXRzz+nj17QvoOHDhgah87dkzbtm1TXV1dqxZ7A5CaWsqvRGWVJH3++edh9ye/AAQEsqumpsaUC9HkVLiMkqzlVDhkF4CAQHaNGzfO9HztaHIqXEZJ1nIqnEiyy9ZHhgEAAAAA0JZRdAMAAAAAYBOKbgAAAAAAbELRDQAAAACATRKykNqKFSvUsWPHYP9VV10Vsm24B6J7PB5b53ciFvMAcKJAflVXV5uyIdFZFQ75BSAgkF2VlZWmXEh0ToVDdgEICGSXE7CQGgAAAAAACUTRDQAAAACATSi6AQAAAACwCUU3AAAAAAA2aZeIQb///e+b2v369QvZZtq0afGaDgBEbPjw4UpPTw+2ySoATvDmm28qMzMz0dMAgDaJb7oBAAAAALAJRTcAAAAAADah6AYAAAAAwCaWiu558+bJ5XKZXn379rVrbgAQE2QXAKcivwA4EdllZnkhtX79+mn16tXNB2iXkLXYAMASsguAU5FfAJyI7Gpm+Tdv166d8vLyYjqJLVu2hPRNmTIlpmMAaNtilV2fffaZqU1WAbBbLPKLJy0AiDc76kansnxP99atW5Wfn69evXpp/Pjx2rlzZ4vb+v1+eb1e0wsAEsFKdknkF4DkwbkXACciu5pZKrqLior0wgsvaNWqVVqyZIl27NihYcOGyefzhd2+vLxcHo8n+CooKIjJpAHACqvZJZFfAJID514AnIjsMnMZhmG0dufa2lr17NlTjz/+uCZNmhTyc7/fL7/fH2x7vV7HvIF1dXXKyspK9DQA2OB02SWRXwCSE+deAJyorWdXVHezZ2dnq3fv3tq2bVvYn7vdbrnd7miGAICYO112SeQXgOTEuRcAJ2rr2RXVc7rr6+u1fft2nX322bGaDwDYjuwC4FTkFwAnauvZZanonjVrltatW6eKigqtX79eY8aMUXp6uoqLi+2aHwBEjewC4FTkFwAnIrvMLF1evmvXLhUXF6umpkY5OTkaOnSoNm7cqJycHLvmBwBRI7sAOBX5BcCJyC6zqBZSs8rr9crj8cRruKiwmAeAE5FfAJyI7ALgRKmWXVHd0w0AAAAAAFpG0Q0AAAAAgE0ougEAAAAAsAlFNwAAAAAANqHoBgAAAADAJnEtuuO4UHrUnDRXAPZzUiY4aa4A7OWkPHDSXAHYy0l5EMlc41p0+3y+eA4XFSfNFYD9nJQJTporAHs5KQ+cNFcA9nJSHkQy17g+p7upqUm7d+9Wly5d5PP5VFBQoMrKSlufyej1ei2NYxiGfD6f8vPzlZbG1fcAjgvkl2EY6tGjR9Jll0R+AQgV73MvsgtALKRadrWLxSQjlZaWpu7du0uSXC6XJCkrK8vWE9cAK+M45UHsAOInkF9er1dScmaXRH4BMEvUuRfZBSAaqZZdfJwIAAAAAIBNKLoBAAAAALBJwoput9utsrIyud3ulBgHQNtAdgFwqnjkCtkFINZSIbviupAaAAAAAABtSasWUlu8eLEWLFigqqoq9e/fX4sWLVJhYeFp9ztxFbrADfHJhhU0gdTV2uySyC8AiUN2AXAq6sbmjS1ZtmyZkZGRYTz33HPGli1bjMmTJxvZ2dlGdXX1afetrKw0JDniVVlZafWtAZDEoskuwyC/ACQG2QXAqagbm1m+vLyoqEiDBw/WU089Jen4pxAFBQWaOnWqZs+efcp96+rqlJ2drbPOOsv0acCDDz4Ysu3YsWND+g4fPhzS98QTT4Qd6+GHHz7lXE6ntraWx1cAKSSa7JKa82vRokXKzMwM9keTVdHmVEvILyB1xCq7nIDsAlJLLOrGZNKjRw9Tu6mpSbt27YoouyxdXt7Y2KhNmzZpzpw5wb60tDSNGDFCGzZsCNne7/fL7/cH2z6fL7jPiUV3x44dQ/YN93y0jIyMkD7bbnZP0ssYAFhnNbuklvMrMzPTlFmJzqpwyC8gNcQyu5yA7AJSR6zqxmTS0iXkkWSXpRtn9u3bp2PHjik3N9fUn5ubq6qqqpDty8vL5fF4gq+CggIrwwFATFjNLon8ApB4ZBcAp6JuNLN1tYo5c+aorq4u+KqsrLRzOACIGfILgBORXQCcKNWzy9Ll5d26dVN6erqqq6tN/dXV1crLywvZ3u12h72k8tFHHzVdnjlmzJiQbcJdUvDxxx+H9K1bty6iuQNou6xml9Ryft10002mS8rJKgB2iWV2JZOTlxPyer3cyw2kmFjVjYkyaNCgkL4PPvjA1LaSXZa+6c7IyNDAgQO1Zs2aYF9TU5PWrFmjIUOGWDkUAMRNLLKrsbHRrukBQFhkFwCnija/Ui27LD+ne8aMGSopKdGgQYNUWFiohQsXqqGhQRMnTrRjfgAQE9FmV01Njc0zBIBQZBcAp4omv1ItuywX3ePGjdPevXs1d+5cVVVVacCAAVq1alXITfIAkEzILgBORHYBcCryq5nloluSSktLVVpaGuu5AICtosmurl27xng2ABAZsguAU7U2v1Itu1pVdEdr+fLlat++fbD9yiuvhGyzZ8+ekL4DBw6E9H3++eexnRwAhBF49vbtt99uyi+yCkAyC2RXMikpKTG1U+3eTQDRS3R27dixI6Rv3759praVZ4nb+sgwAAAAAADaMopuAAAAAABsQtENAAAAAIBNKLoBAAAAALBJQhZSe+uttxIxLABEjfwCgOi89NJLiZ4CAJxSuOeE33333ab2kSNHIj4e33QDAAAAAGATim4AAAAAAGxC0Q0AAAAAgE0ougEAAAAAsElCFlIDAAAAAMApli9f3up9+aYbAAAAAACbUHQDAAAAAGATim4AAAAAAGxC0Q0AAAAAgE0sFd3z5s2Ty+Uyvfr27WvX3AAgJsguAE5FfgFwIrLLzPLq5f369dPq1aubD9COBdABJD+yC4BTkV8AnIjsamb5N2/Xrp3y8vIi2tbv98vv9wfbXq/X6nAAEBNWsksivwAkD869ADgR2dXM8j3dW7duVX5+vnr16qXx48dr586dLW5bXl4uj8cTfBUUFEQ1WQBoLSvZJZFfAJIH514AnIjsauYyDMOIdON3331X9fX16tOnj/bs2aP58+frq6++0qeffqouXbqEbB/uEwunvIF1dXXKyspK9DQAxIDV7JLILwDJgXMvAE5EdplZKrpPVltbq549e+rxxx/XpEmTTru91+uVx+Np7XBxRfADqctqdknkF4DkwLkXACdq69kV1SPDsrOz1bt3b23bti2awwBAXJFdAJyK/ALgRG09u6Iquuvr67V9+3adffbZsZoPANiO7ALgVOQXACdq69llqeieNWuW1q1bp4qKCq1fv15jxoxRenq6iouL7ZofAESN7ALgVOQXACciu8wsPTJs165dKi4uVk1NjXJycjR06FBt3LhROTk5ds0PAKJGdgFwKvILgBORXWZRLaRmVardEA+g7SC/ADgR2QXAiVItu6K6pxsAAAAAALSMohsAAAAAAJtQdAMAAAAAYBOKbgAAAAAAbBLXojuOa7ZFzUlzBWA/J2WCk+YKwF5OygMnzRWAvZyUB5HMNa5Ft8/ni+dwUXHSXAHYz0mZ4KS5ArCXk/LASXMFYC8n5UEkc43rI8Oampq0e/dudenSRT6fTwUFBaqsrLT18RBer9fSOIZhyOfzKT8/X2lpXH0P4LhAfhmGoR49eiRddknkF4BQ8T73IrsAxEKqZVe7WEwyUmlpaerevbskyeVySZKysrLi8kxGK+M45ZlwAOInkF9er1dScmaXRH4BMEvUuRfZBSAaqZZdfJwIAAAAAIBNKLoBAAAAALBJwoput9utsrIyud3ulBgHQNtAdgFwqnjkCtkFINZSIbviupAaAAAAAABtSasWUlu8eLEWLFigqqoq9e/fX4sWLVJhYeFp9ztxFbrADfHJhhU0gdTV2uySyC8AiUN2AXAq6sbmjS1ZtmyZkZGRYTz33HPGli1bjMmTJxvZ2dlGdXX1afetrKw0JDniVVlZafWtAZDEoskuwyC/ACQG2QXAqagbm1m+vLyoqEiDBw/WU089Jen4pxAFBQWaOnWqZs+efcp96+rqlJ2dbWW4mAosO3+ijIwMU7upqUkVFRWqra3l8RVACokmu6T45lckWSUd/51OdOTIEa1YsYL8AlJIMmZXuIySIsspSRoyZIipfejQIf3kJz8hu4AUk8i6MdJzqcA8T3ZyTkkKmc+hQ4d01113RZRdli4vb2xs1KZNmzRnzpxgX1pamkaMGKENGzaEbO/3++X3+4Ntn89nZbiYC/e1f0uXAiTrZQwArLOaXVJi8yvSrGrp/3mQX0BqSNbsauncKdKcyszMDLs/2QWkjkTXjVbqvkhzqmPHjmH3jyS7LN04s2/fPh07dky5ubmm/tzcXFVVVYVsX15eLo/HE3wVFBRYGQ4AYsJqdknkF4DEI7sAOBV1o5mtq1XMmTNHdXV1wVdlZaWdwwFAzJBfAJyI7ALgRKmeXZYuL+/WrZvS09NVXV1t6q+urlZeXl7I9m63O2HPaRwwYEBI3/vvvx/Sd/L1916vl/uJgBRjNbuk+ORXuJySIsuqcLxer1577bUoZwUgWSRDdkV6PiVFllPheL1e3XPPPa3aF0Byimfd2Nq6L1perzfibS19052RkaGBAwdqzZo1wb6mpiatWbMm7M3mAJAMyC4ATkR2AXAq8svM8nO6Z8yYoZKSEg0aNEiFhYVauHChGhoaNHHiRDvmBwAxEW12NTY22jxDAAhFdgFwqmjyK9Wyy3LRPW7cOO3du1dz585VVVWVBgwYoFWrVoXcJA8AySTa7KqpqbF5hgAQiuwC4FTR5FeqZZfloluSSktLVVpaGuu5AICtyC4ATkR2AXAq8uu4VhXdTrBz586QvnCfmLBoGoBIdO3aNebHDJdTElkFIHaiza5Iz6ckcgpA7FjJLifUfbY+MgwAUkVGRkaipwAAlpFdAJwo1bKLohsAAAAAAJtQdAMAAAAAYBOKbgAAAAAAbJKyC6nt378/pG/mzJkhfaNHjza1Dx06ZNucAOBE4XJKiiyrJOmjjz4ytVPtmZYAEi/S8ykpspySpEWLFkU/MQD4/1pb9wXEI6f4phsAAAAAAJtQdAMAAAAAYBOKbgAAAAAAbELRDQAAAACATVyGYRjxGszr9crj8cRruIhkZWWZ2oZhyOfzqa6uLuRnANquROdXuDzy+XymdiDOyS8AAfHMrkhySpKeeeYZU/vQoUO65557yC4AQXZkV0v5EklOSdKdd95pagfmGEl28U03AAAAAAA2oegGAAAAAMAmFN0AAAAAANiEohsAAAAAAJtYKrrnzZsnl8tlevXt29euuQFATJBdAJyK/ALgRGSXWTurO/Tr10+rV69uPkA7y4dIKl6vN9FTABAHTs8usgpou5ySX5HmVF1dnal9+PBhO6YDIMGSLbusnEudnFPRsvybt2vXTnl5eRFt6/f75ff7g21OGgEkipXsksgvAMmDcy8ATkR2NbN8T/fWrVuVn5+vXr16afz48dq5c2eL25aXl8vj8QRfBQUFUU0WAFrLSnZJ5BeA5MG5FwAnIruauQzDMCLd+N1331V9fb369OmjPXv2aP78+frqq6/06aefqkuXLiHbh/vEwilvYCQPOQfgDFazSyK/ACSHVDz3euyxx0ztw4cP67777iO7gBTi9Ow6OackaebMmaa21+uVx+OJKLssXV4+atSo4P++9NJLVVRUpJ49e2r58uWaNGlSyPZut1tut9vKEAAQc1azSyK/ACQHzr0AOBHZZRbV3ezZ2dnq3bu3tm3bFqv5AIDtyC4ATpUK+VVWVmZqW7joEoBDOS27Ts4pSRo0aJCp3dDQEPHxonpOd319vbZv366zzz47msMAQFyRXQCcivwC4ERtPbssFd2zZs3SunXrVFFRofXr12vMmDFKT09XcXGxXfMDgKiRXQCcivwC4ERkl5mly8t37dql4uJi1dTUKCcnR0OHDtXGjRuVk5Nj1/wAIGpkFwCnIr8AOBHZZWap6F62bJld8wAA25BdAJyK/ALgRGSXWVQLqQEAAABWWFl8CAASIVxOnbzqelNTU8THi2ohNQAAAAAA0DKKbgAAAAAAbELRDQAAAACATeJ6T7dhGPEcLipOmisA+zkpE5w0VwD2clIeOGmuAOyVjHlw8j3cgXYkc41r0e3z+eI5XFR8Pp88Hk+ipwEgSZBfAJyI7ALgRMmYXTt27AjbH0l2uYw4fozQ1NSk3bt3q0uXLvL5fCooKFBlZaWysrJsG9Pr9VoaxzAM+Xw+5efnKy2Nq+8BHBfIL8Mw1KNHj6TLLon8AhAq3udeZBeAWEi17IrrN91paWnq3r27JMnlckmSsrKybD1xDbAyDp+yAjhZIL+8Xq+k5MwuifwCYJaocy+yC0A0Ui27+DgRAAAAAACbUHQDAAAAAGCThBXdbrdbZWVlcrvdKTEOgLaB7ALgVPHIFbILQKylQnbFdSE1AAAAAADaEi4vBwAAAADAJhTdAAAAAADYhKIbAAAAAACbUHQDAAAAAGATim4AAAAAAGySsKJ78eLFOvfcc9WhQwcVFRXpb3/7W8yOPW/ePLlcLtOrb9++MTs+gLbLzuySyC8A9iC7ADhRqmRXQoru119/XTNmzFBZWZk+/PBD9e/fXyNHjtTXX38dszH69eunPXv2BF9//vOfY3ZsAG1TPLJLIr8AxBbZBcCJUim7ElJ0P/7445o8ebImTpyoiy66SE8//bQ6duyo5557LmZjtGvXTnl5ecFXt27dYnZsAG1TPLJLIr8AxBbZBcCJUim74l50NzY2atOmTRoxYkTzJNLSNGLECG3YsCFm42zdulX5+fnq1auXxo8fr507d8bs2ADannhll0R+AYgdsguAE6VadsW96N63b5+OHTum3NxcU39ubq6qqqpiMkZRUZFeeOEFrVq1SkuWLNGOHTs0bNgw+Xy+mBwfQNsTj+ySyC8AsUV2AXCiVMuudjE9WpIYNWpU8H9feumlKioqUs+ePbV8+XJNmjQpgTMDgFMjvwA4EdkFwInilV1x/6a7W7duSk9PV3V1tam/urpaeXl5toyZnZ2t3r17a9u2bbYcH0DqS0R2SeQXgOiQXQCcKNWyK+5Fd0ZGhgYOHKg1a9YE+5qamrRmzRoNGTLEljHr6+u1fft2nX322bYcH0DqS0R2SeQXgOiQXQCcKNWyKyGXl8+YMUMlJSUaNGiQCgsLtXDhQjU0NGjixIkxOf6sWbM0evRo9ezZU7t371ZZWZnS09NVXFwck+MDaJvszi6J/AIQe2QXACdKpexKSNE9btw47d27V3PnzlVVVZUGDBigVatWhdwo31q7du1ScXGxampqlJOTo6FDh2rjxo3KycmJyfEBtE12Z5dEfgGIPbILgBOlUna5DMMwYnpEAAAAAAAgKQH3dAMAAAAA0FZQdAMAAAAAYBOKbgAAAAAAbELRDQAAAACATSi6AQAAAACwCUU3AAAAAAA2oegGAAAAAMAmFN0AAAAAANiEohsAAAAAAJtQdAMAAAAAYBOKbgAAAAAAbPL/AOCt5WOTfRTeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create patches from the first image (the 5 on the left of the above figure)\n",
    "\n",
    "patch_size = 8\n",
    "patches = image.extract_patches_2d(X_train[0], (patch_size, patch_size))\n",
    "\n",
    "count=-1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=8, ncols=4, figsize=(15, 5))\n",
    "# plt.tight_layout(w_pad=0.25)\n",
    "for i in range(8) :\n",
    "    for j in range(4) :\n",
    "        count += 1\n",
    "        im = axs[i][j].imshow(patches[100 + count], cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "plt.suptitle(\"Patches of images from the MNIST dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_patches = []\n",
    "list_test_patches = []\n",
    "\n",
    "for i in range(10000):\n",
    "    patches = image.extract_patches_2d(X_train[i], (patch_size, patch_size))\n",
    "    for j in range(patches.shape[0]):\n",
    "        list_train_patches.append(patches[j])\n",
    "\n",
    "for i in range(10000):\n",
    "    patches = image.extract_patches_2d(X_test[i], (patch_size, patch_size))\n",
    "    for j in range(patches.shape[0]):\n",
    "        list_test_patches.append(patches[j])\n",
    "\n",
    "list_train_patches = np.array(list_train_patches)\n",
    "list_test_patches = np.array(list_test_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.431e+01, tolerance: 4.158e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Center X\n",
    "# X_centered = X - np.mean(X)\n",
    "\n",
    "# Learn the online dictionary\n",
    "k = 32\n",
    "Dictionary = online_dictionary_learning(list_train_patches, k, nb_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the dictionary\n",
    "count=-1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=8, ncols=4, figsize=(15, 5))\n",
    "# plt.tight_layout(w_pad=0.25)\n",
    "for i in range(8) :\n",
    "    for j in range(4) :\n",
    "        count += 1\n",
    "        im = axs[i][j].imshow(Dictionary[:,count].reshape(8, 8), cmap=plt.get_cmap('gray'))\n",
    "\n",
    "fig.tight_layout(pad=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/admin/Desktop/ALL/ENS/StatML/Compressed Sensing/Dictionary Learning (GitHub)/Compressed_Sensing.ipynb Cell 46'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000052?line=0'>1</a>\u001b[0m Dictionary_stochastic \u001b[39m=\u001b[39m stochastic_dictionary_learning(X_train, k, nb_iter\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m)\n",
      "\u001b[1;32m/Users/admin/Desktop/ALL/ENS/StatML/Compressed Sensing/Dictionary Learning (GitHub)/Compressed_Sensing.ipynb Cell 39'\u001b[0m in \u001b[0;36mstochastic_dictionary_learning\u001b[0;34m(X, k, nb_iter)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=57'>58</a>\u001b[0m     reg\u001b[39m.\u001b[39mfit(D, X_sample) \u001b[39m# Update alpha\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=58'>59</a>\u001b[0m     alpha \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mcoef_\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=60'>61</a>\u001b[0m     D \u001b[39m=\u001b[39m stochastic_dictionary_update(D, alpha, X) \u001b[39m# Update D\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=62'>63</a>\u001b[0m     \u001b[39mprint\u001b[39m(i)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m D\n",
      "\u001b[1;32m/Users/admin/Desktop/ALL/ENS/StatML/Compressed Sensing/Dictionary Learning (GitHub)/Compressed_Sensing.ipynb Cell 39'\u001b[0m in \u001b[0;36mstochastic_dictionary_update\u001b[0;34m(D_init, alpha, X, maxiter, step)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=27'>28</a>\u001b[0m     D \u001b[39m=\u001b[39m D \u001b[39m-\u001b[39m step \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m grad_i(D, alpha, X_sample) \u001b[39m# SGD with decaying step\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=29'>30</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(D\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=30'>31</a>\u001b[0m         D[:,i] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m \u001b[39mmax\u001b[39m(np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(D[:,i]), \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m D[:,i] \u001b[39m# Projection onto the set C\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/admin/Desktop/ALL/ENS/StatML/Compressed%20Sensing/Dictionary%20Learning%20%28GitHub%29/Compressed_Sensing.ipynb#ch0000042?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m D\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test-project/lib/python3.8/site-packages/numpy/linalg/linalg.py:2520\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2515\u001b[0m ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mndim\n\u001b[1;32m   2516\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mord\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   2517\u001b[0m     (\u001b[39mord\u001b[39m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfro\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m ndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   2518\u001b[0m     (\u001b[39mord\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m ndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m-> 2520\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mravel(order\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mK\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m   2521\u001b[0m     \u001b[39mif\u001b[39;00m isComplexType(x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype):\n\u001b[1;32m   2522\u001b[0m         x_real \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreal\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Dictionary_stochastic = stochastic_dictionary_learning(X_train, k, nb_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-d56fd179-88d2-44a0-8699-7e41566b20f4",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 4. Some insights into more recent uses of dictionary learning\n",
    "\n",
    "### 4.1 From euclidean dictionaries to general dictionaries\n",
    "\n",
    "If we forget for a moment the $\\ell_1$ penalty, the remaining objective function that we want to minimize to compute the representation of a single vector $\\mathbf{x}$ with respect to a dictionary $\\mathbf{D}$ is\n",
    "\n",
    "$$\n",
    "\\underset{\\alpha_1, \\dots, \\alpha_k}{\\min} \\lVert \\mathbf{x} - \\sum_{i=1}^k \\alpha_i \\mathbf{d}_i \\rVert^2\n",
    "$$\n",
    "\n",
    "Which can be interpreted as  \"finding the barycenter of atoms $\\mathbf{d}_1, \\dots, \\mathbf{d}_k$ that is closest to $\\mathbf{x}$ with respect to the euclidean distance. This being said, we can replace the euclidean distance with any other distance that will better take into account the natural geometry of the problem at hand, and that geometry does not have to be the natural euclidean geometry. This is how we can generalize the idea of dictionary learning to any other type of data lying in a metric space $(\\mathcal{E}, d)$. In such a setting the coefficients are computed in two steps : given some coefficients $\\alpha_1, \\dots, \\alpha_k$, the barycenter of the atoms is defined as \n",
    "\n",
    "$$\n",
    "\\mathbf{d}^*(\\alpha_1, \\dots, \\alpha_k) = \\underset{\\mathbf{d} \\in \\mathcal{E}}{\\arg \\min} \\sum_{i=1}^k \\alpha_i \\, d(\\mathbf{d}, \\mathbf{d}_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00041-0d445b67-3b6e-4000-85bf-2e565b11dcd6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "then the optimal coefficients for a point $\\mathbf{x}$ are defined as \n",
    "\n",
    "$$\n",
    "\\alpha_1^*, \\dots, \\alpha_k^* = \\underset{\\alpha_1, \\dots, \\alpha_k}{\\arg \\min} d(\\mathbf{x}, \\mathbf{d}^*(\\alpha_1, \\dots, \\alpha_k))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-02ac23a0-6270-4397-bc4e-6b59fc7055e5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 4.2 Dictionaries in Topological Data Analysis\n",
    "\n",
    "One of the core tools in topological data analysis (TDA) is the persistence diagram. It is an object that encapsulates a simple topological signature of complex objects, typically compact submanifolds of $\\mathbb{R}^d$ Here the sparsity lies in the fact that we can represent some very complicated topological objects by a much simpler _summary_. The point here is not to delve into the details of TDA, but to show a less straightforward use of dictionary learning. One of the key ideas of TDA is to only store compact representations of data instead of the data itself. This idea is viable due to the fact that persistence diagrams enjoy a lot of stability properties that makes them \"good\" representations of the data in some sense. Once the space of persistence diagrams is endowed with a metric, it is then possible to define the notion of dictionaries and mixing coefficients just like in the classical euclidean setting, with the general notion of dictionary and coefficients explained above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-f1fed19c-0098-496c-9eb3-8f6695efa886",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<img src=\"persistence_diagrams.jpg\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-de25d542-725e-43f9-86e7-bedeb47e70a9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-998b4146-044b-47aa-b554-8ae05b2050d2",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The space of persistence diagrams can be endowed with a family of Wasserstein-like distance functions. A diagram can be seen as a discrete measure in $\\mathbb{R}^2$ so it can be equiped with the classical $p$-Wasserstein distances $W_p$. \n",
    "\n",
    "<img src=\"distance_between_diagrams.jpg\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-1608334b-7d04-48e3-8cb9-f75a3f3d5b8d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "the two illustrations above were taken from Frederic Chazal's course (see https://geometrica.saclay.inria.fr/team/Fred.Chazal/M2Orsay2021.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00047-0e9a89e1-2b97-4bc2-9fa0-092053affc45",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "In dictionary learning, the goal is to find a _sparse_ representation of a vector $\\mathbf{x}$ in a dictionary $\\mathbf{D}$. That is to say, $\\mathbf{x} \\approx \\sum_{i=1}^k \\alpha_i \\mathbf{d}_i$, and we aim at finding both the dictionary $\\mathbf{D}$ and the coefficients $\\boldsymbol{\\alpha}$.\n",
    "We presented two algorithms for adaptive dictionary learning : supervised dictionary learning and online dictionary learning. The first one aims at learning both a classifier and the dictionary with the associated coefficients, while the latter propose an alternative to batch methods which could be too computationally intensive in high-dimension. We fully implemented the two algorithms and showed that the second one was able to learn the sparse representation of $\\mathbf{x}$. Our first algorithm works on a toy example but takes too long to converge with a real dataset."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Compressed Sensing - Chardon Jolivet.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e772703b-90a3-433c-afdf-5f98bc800cb6",
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f9513a21945f89eeec10807dcdae6d2daf7ea2ab59e5a200b4b192b7abf59f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
